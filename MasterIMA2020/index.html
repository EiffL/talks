<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Signal Processing for Astronomy</title>

	<meta name="description" content="Signal Processing for Astronomy">
	<link rel="stylesheet" href="reveal.js/dist/reset.css">
	<link rel="stylesheet" href="reveal.js/dist/reveal.css">
	<link rel="stylesheet" href="reveal.js/dist/theme/darkenergy.css" id="theme">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css" id="highlight-theme">
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section data-background-image="assets/lsst_stills_0009_crop.jpg">
				<div class="container">
					<div class="title" style="border-radius: 20px; background-color:rgba(0, 0, 0, 0.4);">
						<h1>Signal Processing for Astronomy</h1>
						<h2>from Wavelets to <b>Deep Learning</b></h2>
					</div>
				</div>
				<!-- <div style="border-radius: 20px; background-color:rgba(0, 0, 0, 0);">
					<div class="container">
						<div class="col">
							<div align="left" style="margin-left: 20px;">
								<h2>François Lanusse</h2>
								<br>
								<img src="assets/CosmoStatDarkBK.png" class="plain"></img>
								<br>
							</div>
						</div>

						<div class="col">
							<br>
							<br>
							<br>
							<br>
							<img src="assets/logo_cnrs.png" class="plain" height="150"></img>
						</div>

						<div class="col">
							<br>

							<br>
							<br>
							<img src="assets/aim.png" class="plain" height="150"></img>
						</div>
					</div>
				</div> -->
			</section>

			<section data-background-image="assets/WMAP_timeline_large.jpg">
				<h3 class='slide-title' style="position:absolute;top:0;"> the $\Lambda$CDM view of the Universe </h3>
				<br> <br>
				<div class="container">
					<div class="col" style="flex: 0 0 40em;">

					</div>
					<div class="col">

						<img class="plain" data-src="assets/Euclid.png" style="width: 300px" />

						<img class="plain" data-src="assets/wfirstlogo.png" style="width: 300px" />

						<img class="plain" data-src="assets/vrro.png" style="width: 300px" />
					</div>
				</div>
				<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
			</section>

			<section>
				<section data-background-video="assets/animation-day-to-night.mov" data-background-video-muted>
					<h3 class='slide-title'>the Rubin Observatory Legacy Survey of Space and Time</h3>
					<div class="container">
						<div class="col">
							<ul>
								<li class="fragment fade-up"> 1000 images each night, 15 TB/night for 10 years</li>
								<br>
								<li class="fragment fade-up"> 18,000 square degrees, observed once every few days</li>
								<br>
								<li class="fragment fade-up"> Tens of billions of objects, each one observed $\sim1000$ times</li>
							</ul>
							<br>
							<p class="fragment fade-up"> $\Longrightarrow$ Incredible potential for discovery, along with <b>unprecedented challenges</b>.</p>
						</div>

						<div class="col">
							<video class="fragment fade-up" data-fragment-index="1" data-autoplay data-src="assets/obsim.mp4" type="video/mp4" />
						</div>
					</div>
				</section>

				<section data-transition="fade-in fade-out" data-background="assets/gal_sdss.png" data-vertical-align-top>
					<p>Previous generation survey: SDSS</p>
					<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
					<br> <br> <br> <br> <br> <br> <br>
					<div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
				</section>
				<section data-transition="fade-in fade-out" data-background="assets/gal_des.png" data-vertical-align-top>
					<p>Current generation survey: DES</p>
					<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
					<br> <br> <br> <br> <br> <br> <br>
					<div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
				</section>
				<section data-transition="fade-in fade-out" data-background="assets/gal_hsc.png" data-vertical-align-top>
					<p>LSST precursor survey: HSC</p>

					<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
					<br> <br> <br> <br> <br> <br> <br>
					<div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
				</section>
			</section>

			<section data-background-image="assets/gravitational-lensing-diagram.jpg">
				<h3 class="slide-title"> The weak lensing shape measurement problem</h3>
				<div class="fragment fade-up">
					<img class="plain" data-src="assets/great.jpg" />
				</div>

				<div class="block fragment">
					<div class="block-title">
						Galaxy shape measurement
					</div>
					<div class="block-content">
						$$ e = \gamma + e_i \qquad \mbox{ with } \qquad e_i \sim \mathcal{N}(0, I)$$

						<ul>
							<li> We are trying the measure the <b class="alert"> ellipticity $e$</b> of
								galaxies as an estimator for the <b class="alert">gravitational shear $\gamma$ </b>
							</li>
							<li> Extremely difficult measurement, needs to take into account the PSF of the instrument,
								noise, and shape of galaxies.
							</li>
						</ul>
					</div>
				</div>
			</section>

			<section>
				<section data-background="assets/gal_hsc.png">

				</section>
				<section>
					<h3 class="slide-title">The challenge of galaxy blending</h3>
					<div class="container">
						<div class="col">
							<div style="position:relative; width:480px; height:500px; margin:0 auto;">
								<img class="fragment current-visible plain" data-src="assets/hsc_deblending_success.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
								<img class="fragment plain" data-src="assets/hsc_shredded.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
							</div>
							<div class="fragment" data-fragment-index="0" style="float:left; font-size: 20px">Bosch et al. 2017</div>
						</div>
						<div class="col">
							<ul>
								<li class="fragment fade-up" data-fragment-index="0"> In HSC over 60% of all galaxies are blended</li>
								<br>
								<li class="fragment fade-up" data-fragment-index="0"> Important impact on our main cosmological probes</li>
								<br>
								<li class="fragment fade-up" data-fragment-index="1"> Current generation of deblenders does not meet our target requirements</li>
								<br>
								<ul class="fragment fade-up" data-fragment-index="2">
									<li> Existing methods rely on simple assumptions about galaxy profiles, like <i>symmetry</i> or <i>monotonicity</i></li>
								</ul>
							</ul>
						</div>
					</div>

					<div class="fragment fade-up" data-fragment-index="3">
						Deblending is an ill-posed inverse problem, akin to <b class="alert">Blind Source Separation</b>. The is no <b>single solution</b>.<br>
						$\Longrightarrow$ Intuitively, the key will to leverage an understanding of how individual <i>galaxies look like</i>.
					</div>
				</section>
			</section>
			<!--
			<section>
				<section>
					<h3 class="slide-title">Deep Learning applied to deblending (Reiman & Gohre 2018)</h3>
					<div>
						<img class="plain" data-src="assets/Reiman2018_1.png" />
						Branched GAN model for deblending
					</div>

					<div class="block fragment">
						<div class="block-title">
							The issue with <i>black-box</i> models
						</div>
						<div class="block-content">
							<ul>
								<li> No explicit control of noise, PSF, depth, number of sources.
									<ul>
										<li> Model would have to be retrained for all observing configurations
										</li>
									</ul>
								</li>
								<br>
								<li> No guarantees on the network output (e.g. flux preservation, artifacts)
								</li>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<img class="plain" data-src="assets/Reiman2018_2.png" />
				</section>
			</section> -->

			<section>
				<!-- <section>
					<h3 class="slide-title">Linear inverse problems</h3>

					$\boxed{y = \mathbf{A}x + n}$
					<br>
					<br>
					$\mathbf{A}$ is known and encodes our physical understanding of the problem.
					<span class="fragment"><br>$\Longrightarrow$ When non-invertible or ill-conditioned, the inverse problem is ill-posed with no unique solution $x$</span>
					<div class="container fragment fade-up">
						<div class="col">
							<img data-src="assets/pluto_smooth.png" class="plain"></img>
							Deconvolution
						</div>
						<div class="col">
							<img data-src="assets/pluto_missing.png" class="plain"></img>
							Inpainting
						</div>
						<div class="col">
							<img data-src="assets/plutoNoise.png" class="plain"></img>
							Denoising
						</div>
					</div>

				</section> -->

				<section data-vertical-align-top>
					<h3 class="slide-title">Linear inverse problems</h3>
					$\boxed{y = \mathbf{A}x + n}$
					<br>
					<br>
					The Bayesian view of the problem:
					<br>
					<br>
					$$ p(x | y) \propto p(y | x) \ p(x) $$
					<br>

					<ul>
						<li class="fragment fade-up">$p(y | x)$ is the data likelihood, which <b>contains the physics</b><br>
						</li>
						<br>
						<li class="fragment fade-up"><b class="alert">$p(x)$ is our prior knowledge</b> on the solution.</li>
					</ul>
					<br>
					<br>
					<div class="fragment fade-up">
						With these concepts in hand, we want to estimate the Maximum A Posteriori solution:
						<br>
						<br>
						$$\hat{x} = \arg\max\limits_x \ \log p(y \ | \ x) + \log p(x)$$
						<br>
						For instance, if $n$ is Gaussian, $\hat{x} = \arg\max\limits_x \ \frac{1}{2} \parallel y - \mathbf{A} x \parallel_{\mathbf{\Sigma}}^2 + \log p(x)$
					</div>
					<br>
					<div class="fragment fade-up">
						<h3>How do you choose the prior ?</h3>
					</div>
				</section>

				<section>
					<h3 class="slide-title"> Classical examples of signal priors </h3>
					<div class="container">
						<div class="col">
							Sparse
							<img data-src="assets/wavelet.png" height="400" class="plain"></img><br>
							$$ \log p(x) = \parallel \mathbf{W} x \parallel_1 $$
						</div>
						<div class="col">
							Gaussian
							<img data-src="assets/zknj8.jpg" height="400" class="plain"></img>
							$$ \log p(x) = x^t \mathbf{\Sigma^{-1}} x $$
						</div>
						<div class="col">
							Total Variation
							<img data-src="assets/shepp-Logan.ppm" class="plain"></img>
							$$ \log p(x) = \parallel \nabla x \parallel_1 $$

						</div>
					</div>
				</section>

				<section data-background="assets/hsc_screen.png">
					<h2>But what about this?</h2>

				</section>
			</section>

			<section class="inverted" data-background="#000">
				<h2>
					Can we use Deep Learning to learn the prior $\log p(x)$ from data?</h2>
			</section>

			<section data-background-iframe="https://www.thispersondoesnotexist.com/">
				<h3 class="slide-title" style="background: rgba(0, 0, 0, 0.3);"> Do you know this person?</h3>

				<br><br><br>
				<br><br><br>
				<br><br><br>
				<br><br><br>
				<br><br><br>
				<br><br><br>

				<div class="fragment fade-up">
					<p>Probably not, this is a randomly generated person: <a href="https://www.thispersondoesnotexist.com/" target="_blank">thispersondoesntexist.com</a></p>
				</div>
			</section>

			<section>

				<section>
					<h3 class="slide-title"> What is generative modeling?</h3>
					<br>
					<br>
					<ul>
						<li>The goal of generative modeling is to <b>learn the distribution $\mathbb{P}$</b>
							from which the <b>training set $X = \{x_0, x_1, \ldots, x_n \}$</b> is drawn.
						</li>
						<br>
						<li class='fragment'> Usually, this means building a parametric model $\mathbb{P}_\theta$
							that tries to be close to $\mathbb{P}$. 
						</li>
					</ul>

					<br>
					<br>

					<div class="container">

						<div class="col fragment fade-up">
							<img data-src="https://s3.amazonaws.com/media-p.slid.es/uploads/866922/images/7756538/pasted-from-clipboard.png" class="plain"></img>
							<br>
							True $\mathbb{P}$
						</div>

						<div class="col  fragment fade-up">
							<img data-src="https://s3.amazonaws.com/media-p.slid.es/uploads/866922/images/7756539/pasted-from-clipboard.png" class="plain"></img>
							<br>
							Samples $x_i \sim \mathbb{P}$
						</div>

						<div class="col  fragment fade-up">
							<img data-src="https://s3.amazonaws.com/media-p.slid.es/uploads/866922/images/7756554/pasted-from-clipboard.png" class="plain"></img>
							<br>
							Model $\mathbb{P}_\theta$
						</div>
					</div>

				</section>

				<section>
					<h3 class="slide-title">Why isn't it easy?</h3>
					<br>
					<ul>
						<li> The <b class="alert">curse of dimensionality</b> put all points far apart in high dimension
						</li>
					</ul>
					<div class="container">
						<div class="col fragment fade-up">
							<img data-src="https://s3.amazonaws.com/media-p.slid.es/uploads/866922/images/7756597/pasted-from-clipboard.png" class="plain"></img>
						</div>

						<div class="col fragment fade-up">
							<img style="height:350px;" data-src="https://developers.google.com/machine-learning/clustering/images/CurseofDimensionality.svg" class="plain"></img>
							<br>Distance between pairs of points drawn from a Gaussian distribution.
						</div>
					</div>

					<br>
					<ul>
						<li class="fragment"><b>Classical methods</b> for estimating probability densities, i.e. Kernel Density Estimation (KDE) start to <b>fail in high dimension</b> because of all the gaps
						</li>
					</ul>
				</section>
			</section>

			<section>
				<h3 class="slide-title"> The evolution of generative models </h3>

				<br> <br> <br>
				<div class='container'>
					<div class='col'>
						<div style="position:relative; width:500px; height:500px; margin:0 auto;">
							<img class="fragment current-visible plain" data-src="assets/DBN.png" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="0" />
							<img class="fragment current-visible plain" data-src="assets/vae_faces.jpg" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="1" />
							<img class="fragment current-visible plain" data-src="assets/gan-samples-1.png" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="2" />
							<img class="fragment plain" data-src="assets/karras2017.png" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="3" />
						</div>
					</div>

					<div class='col'>
						<ul>
							<li class="fragment" data-fragment-index="0"> Deep Belief Network <br> (Hinton et al. 2006) </li>
							<br>
							<li class="fragment" data-fragment-index="1"> Variational AutoEncoder <br> (Kingma & Welling 2014) </li>
							<br>
							<li class="fragment" data-fragment-index="2"> Generative Adversarial Network <br> (Goodfellow et al. 2014)</li>
							<br>
							<li class="fragment" data-fragment-index="3"> Wasserstein GAN <br> (Arjovsky et al. 2017) </li>
						</ul>
					</div>
				</div>
				<br> <br> <br>
			</section>

			<section>
				<h3 class="slide-title"> A visual Turing test </h3>
				<div class="container">
					<div class="col">
						<img data-src="assets/samples_pixel_cnn.png" class="plain" style="height: 500px;"></img>
						<br>
						<div class="fragment fade-up" data-fragment-index="0"> Fake PixelCNN samples </div>
					</div>
					<div class="col">
						<img data-src="assets/sdss5.png" class="plain" style="height: 500px;"></img>
						<br>
						<div class="fragment fade-up" data-fragment-index="0"> Real galaxies from SDSS </div>
					</div>
				</div>
			</section>

			<section>
				<section>
					<h3 class="slide-title"> The many flavors of Generative Models </h3>
					<ul>
						<li> <b class='alert'>Likelihood-free approach</b>: Generative Adversarial Networks
						</li>
					</ul>
					<div class="container">
						<div class="col">
							<img data-src="assets/gan_illustration.png" style="width:550px"></img>
						</div>
						<div class="col fragment fade-up">
							<img data-src="assets/gen_models_diag_2.svg" style="background: #BBB;width:550px;"></img>
							<br>
							<div style="float:right; font-size: 20px">Image credit: <a href="https://blog.openai.com/generative-models/">OpenAI</a></div>
						</div>
					</div>
					<ul>
						<li class="fragment">The WGAN (Arjovsky et al. 2017) is based on the Wasserstein distance between real $\mathbb{P}_r$ and generated $\mathbb{P}_\theta$ distributions:
							<br>
							<br>
							$$W(\mathbb{P}_r, \mathbb{P}_\theta) = \sup\limits_{||f_{\phi}||_L \leq 1} \mathbb{E}_{x \sim \mathbb{P}_r}[f_{\phi}(x)] - \underbrace{\mathbb{E}_{x \sim \mathbb{P}_\theta}[f_\phi(x)]}_{=\mathbb{E}_z[f_\phi(g_{\theta}(z))]}$$
						</li>
						<li class="fragment"> <b class="alert">A GAN can only sample</b> from $\mathbb{P}_\theta$, it cannot evaluate $\log p_\theta(x)$, hence the expression "likelihood-free".
						</li>
					</ul>
				</section>

				<section>
					<ul>
						<li><b class="alert">The Variational Inference approach</b>: Variational Auto-Encoders</li>
					</ul>
					<img data-src="assets/vae.png" class="plain" style="height: 450px;"> </img>
					<br>
					<br>
					$$\log p_\theta(x) \geq - \underbrace{\mathbb{D}_{KL}\left( q_\phi(z | x) \parallel p(z) \right)}_{\mbox{code regularization}} + \underbrace{\mathbb{E}_{z \sim q_{\phi}(. | x)} \left[ \log p_\theta(x
					| z) \right]}_{\mbox{reconstruction error}} $$

					<ul>
						<li class="fragment"> <b class="alert">Only provides a lower-bound on the likelihood</b> $p_\theta(x)$.
						</li>
					</ul>
				</section>

				<section>
					<ul>
						<li><b class="alert">Likelihood-Based Models</b>: PixelCNN
						</li>
					</ul>
					<br>
					<br>
					<div class="container">
						<div class="col">
							Models the probability $p(x)$ of an image $x$ as:
							$$ p_{\theta}(x) = \prod_{i=0}^{n} p_{\theta}(x_i | x_{i-1} \ldots x_0) $$
							<ul>
								<li>Some of the best log-likelihoods on the market.</li>
								<li>Extremely stable during training.</li>
								<li>Slow to sample from.</li>
							</ul>
							<br>
							<br>

							<div class="fragment fade-up">
								<img data-src="assets/speedup.gif" class="plain"></img>
								<br>
								<div style="float:left; font-size: 20px">Ramachandran et al. 2017</div>
							</div>
						</div>

						<div class="col">
							<img data-src="assets/pixel_cnn_conv.png" class="plain"></img>
							<div style="float:right; font-size: 20px">van den Oord et al. 2016</div>
						</div>
					</div>
					<br>
					<ul>
						<li class="fragment"> Provides an explicit value for $\log p_\theta(x)$<br>
							$\Longrightarrow$ <b class="alert">Can easily be used as a prior for inverse problems.</b>
						</li>
					</ul>
				</section>
			</section>

			<section>
				<h3 class="slide-title">A deblending toy example</h3>
				<div class="container">
					<div class="col">
						<div class="fig-container" data-file="dgm_prior.html" data-style="height: 550px;"></div>
						<br>
						Try me out at: <a href="https://eiffl.github.io/DeepPriors">https://eiffl.github.io/DeepPriors</a>
					</div>

					<div class="col">
						<ul>
							<li>Assume a blend with two components $x_1$ and $x_2$ <br> $x_1 + x_2$ must match the data $y$</li>
							<br>
							<li>Each component of the blend should lie on the "realistic galaxy manifold", symbolized by the two-moons distribution.</li>
						</ul>
						<p> We are solving: </p>
						$\arg \max - \frac{1}{2} \parallel {\color{Orchid} y} - {\color{red} \sum_{\color{red} i} {\color{red} x}_{\color{red} i}} \parallel_2^2 + \log p({\color{SkyBlue} x_{\color{SkyBlue} 1}}) + \log p({\color{GreenYellow}
						x_{\color{GreenYellow} 2}}) $
						<br>
						<br>
						This can be done by gradient descent as long as one has access to $\frac{\color{orange} d \color{orange}\log \color{orange}p\color{orange}(\color{orange}x\color{orange})}{\color{orange} d \color{orange}x}$.
					</div>
				</div>
			</section>
			<!--
			<section data-vertical-align-top>
				<h3 class="slide-title">Not all generative models are created equal</h3>
				<img data-src="assets/generative_models_table.png" class="plain"></img>
				<div style="float:right; font-size: 20px">Grathwohl et al. 2018</div>
				<br>
				<br>
				<ul>
					<li> GANs and VAEs are very common and successfull but do not fit our purposes.</li>
					<br>
					<li> We need a model which can provide explicitly $\log p(x)$.</li>
					<br>
				</ul>
			</section>

			<section>
				<h3 class="slide-title">PixelCNN: Likelihood-based Autoregressive generative model</h3>
				<div class="container">
					<div class="col">
						Models the probability $p(x)$ of an image $x$ as:
						$$ p_{\theta}(x) = \prod_{i=0}^{n} p_{\theta}(x_i | x_{i-1} \ldots x_0) $$
						<ul>
							<li>Some of the best log-likelihoods on the market.</li>
							<li>Extremely stable during training.</li>
							<li>Slow to sample from.</li>
						</ul>
						<br>
						<br>

						<div class="fragment fade-up">
							<img data-src="assets/speedup.gif" class="plain"></img>
							<br>
							<div style="float:left; font-size: 20px">Ramachandran et al. 2017</div>
						</div>

					</div>

					<div class="col">
						<img data-src="assets/pixel_cnn_conv.png" class="plain"></img>
						<div style="float:right; font-size: 20px">van den Oord et al. 2016</div>
					</div>
				</div>
			</section> -->

			<section>
				<h3 class="slide-title"> The Scarlet algorithm: deblending as an optimization problem</h3>
				<div style="float:right; font-size: 20px">Melchior et al. 2018</div>

				$$ \mathcal{L} = \frac{1}{2} \parallel \mathbf{\Sigma}^{-1/2} (\ Y - P \ast A S \ ) \parallel_2^2 - \sum_{i=1}^K \log p_{\theta}(S_i) + \sum_{i=1}^K g_i(A_i) + \sum_{i=1}^K f_i(S_i)$$

				<div class="container">
					<div class="col">
						<img data-src="assets/scarlet_data.png" height=450 class="plain"></img>
					</div>

					<div class="col">

						Where for a $K$ component blend:
						<br>
						<ul>
							<li>$P$ is the convolution with the instrumental response</li>
							<br>
							<li>$A_i$ are channel-wise galaxy SEDs, $S_i$ are the morphology models</li>
							<br>
							<li>$\mathbf{\Sigma}$ is the noise covariance</li>
							<br>
							<li>$\log p_\theta$ is a PixelCNN prior</li>
							<br>
							<li>$f_i$ and $g_i$ are arbitrary additional non-smooth consraints, e.g. positivity, monotonicity...</li>
						</ul>
					</div>
				</div>

				<span class="fragment fade-up">$\Longrightarrow$ Explicit physical modeling of the observed sky</span>
			</section>

			<section>
				<h3 class="slide-title">Training the morphology prior</h3>

				<div class="container">
					<div class="col">
						<img data-src="assets/cosmos_training.png" height=450 class="plain"></img>
						<div> Postage stamps of isolated COSMOS galaxies used for training, at WFIRST resolution and fixed fiducial PSF</div>
					</div>

					<div class="col">
						<div class="container fragment fade-in">
							<div class="col">
								isolated galaxy
								<img data-src="assets/gal_1.png" class="plain"></img>
								<span> $\log p_\theta(x) = 3293.7$ </span>
							</div>

							<div class="col">
								artificial blend
								<img data-src="assets/gal_2.png" class="plain"></img>
								<span> $\log p_\theta(x) = 3100.5 $ </span>
							</div>
						</div>
					</div>
			</section>

			<section>
				<section>
					<h3 class="slide-title">Scarlet in action</h3>

					<div class="container">
						<div class="col">
							Input blend
							<div style="position:relative; width:480px; height:480px; margin:0 auto;">
								<img data-src="assets/scar_input.png" class="plain"></img>
							</div>
						</div>

						<div class="col">
							<span class="fragment" data-fragment-index="0">Solution</span>
							<div style="position:relative; width:480px; height:480px; margin:0 auto;">
								<img class="fragment current-visible plain" data-src="assets/old_rec.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
								<img class="fragment  plain" data-src="assets/pix_rec.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
							</div>
						</div>

						<div class="col">
							<span class="fragment" data-fragment-index="0">Residuals</span>
							<div style="position:relative; width:480px; height:480px; margin:0 auto;">
								<img class="fragment current-visible plain" data-src="assets/old_res.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
								<img class="fragment  plain" data-src="assets/pix_res.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
							</div>
						</div>
					</div>

					<ul>
						<li class="fragment fade-up" data-fragment-index="0">Classic priors (monotonicity, symmetry).</li>
						<br>

						<li class="fragment fade-up" data-fragment-index="1">Deep Morphology prior.</li>
					</ul>

				</section>
				<section>
					<div class="container">
						<div class="col">
							True Galaxy
							<img data-src="assets/true_input.png" class="plain"></img>
						</div>

						<div class="col">
							Deep Morphology Prior Solution

							<img class=" plain" data-src="assets/pix_rec2.png" />

						</div>

						<div class="col">
							Monotonicity + Symmetry Solution
							<img class=" plain" data-src="assets/scar_rec2.png" />
						</div>
					</div>
				</section>
			</section>


			<section>
				<h3 class="slide-title"> Extending to multi-band images</h3>

				<img class=" plain" data-src="assets/scarlet_hsc.png" />
				<div style="float:right; font-size: 25px"><b>Lanusse</b>, Melchior, Moolekamp (2019)<br>
				</div>
			</section>

			<section class="inverted" data-background="#000">
				<h2>
					Can we go beyond point estimates with modern Machine Learning techniques?</h2>
			</section>


			<section>
				<section>
					<h3 class="slide-title" style="position:absolute;top:0;">A motivating examples: Image deconvoluion</h3>
					<br>
					<br>
					<div class="container">
						<div class="col">
							<img class="plain" data-src="assets/cosmos_gal.png" style="width: 250px" />
							<br><b class="alert">Hubble Space Telescope</b>
						</div>

						<div class="col fragment fade-up">
							<img class="plain " data-src="assets/generic_network.png" style="height: 250px; width:500px" />
							<br>some deep neural network
						</div>

						<div class="col">
							<img class="plain" data-src="assets/cosmos_gal_ground.png" style="width: 250px" />
							<br><b class="alert">Simulated Ground-Based Telescope</b>
						</div>
					</div>
					<!--
			        <div> <img class="plain" data-src="assets/galaxygan.png"></div> -->
					<br>
					<br>

					<div class="block fragment">
						<div class="block-title">
							The issue with generic black box deep learning inference
						</div>
						<div class="block-content">
							<ul>
								<li class="fragment">No explicit control of noise, PSF, depth.
									<ul>
										<li>Unless covered by the training data, the result becomes unpredictable.
										</li>
									</ul>
								</li>
								<br>
								<li class="fragment">No guarantees some physical properties are preserved
									<br>$\Longrightarrow$ In this case, the flux of the deconvolved object
								</li>
								<br>
								<li class="fragment"><b class="alert">Robust quantification of uncertainties is extremely difficult</b>.
								</li>
							</ul>
							<br>
						</div>
					</div>

				</section>

				<section>
					<h3 class="slide-title" style="position:absolute;top:0;">A Physicist's approach: let's build a model</h3>
					<br>
					<br>
					<div class="container">
						<div class="col">
							<img class="plain fragment" data-src="assets/rand_z_square.png" style="height: 150px" data-fragment-index="4" />
						</div>
						<div class="col">
							<img class="plain fragment" data-src="assets/cosmos_gal.png" style="width: 200px" data-fragment-index="3" />
						</div>
						<div class="col">
							<img class="plain fragment" data-src="assets/cosmos_gal_psf.png" style="width: 200px" data-fragment-index="2" />
						</div>

						<div class="col">
							<img class="plain fragment" data-src="assets/cosmos_gal_pix.png" style="width: 200px" data-fragment-index="1" />
						</div>

						<div class="col">
							<img class="plain fragment" data-src="assets/cosmos_gal_ground.png" style="width: 200px" data-fragment-index="0" />
						</div>
					</div>

					<div class="container" style="position:relative; width:1000px; height:50px; margin:0 auto;">
						<div class='col fragment' data-fragment-index='4'>
							<font size="10"> $\longrightarrow$ </font> <br> $g_\theta$
						</div>
						<div class='col fragment' data-fragment-index='3'>
							<font size="10"> $\longrightarrow$ </font> <br> PSF
						</div>
						<div class='col fragment' data-fragment-index='2'>
							<font size="10"> $\longrightarrow$ </font> <br> Pixelation
						</div>
						<div class='col fragment' data-fragment-index='1'>
							<font size="10"> $\longrightarrow$ </font> <br> Noise
						</div>
					</div>

					<div class="container">
						<div class="col">
							<div style="position:relative; width:400px; height:300px; margin:0 auto;">
								<img data-src="assets/pgm_0.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:300px;" data-fragment-index="0" />
								<img data-src="assets/pgm_1.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:300px;" data-fragment-index="1" />
								<img data-src="assets/pgm_1.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:350px;" data-fragment-index="2" />
								<img data-src="assets/pgm_2.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:350px;" data-fragment-index="3" />
								<img data-src="assets/pgm_3.png" class="plain fragment " style="position:absolute;top:0;left:0;height:300px;" data-fragment-index="4" />
							</div>
						</div>
						<div class=" col">
							<div class="block fragment" data-fragment-index="0">
								<div class="block-title">
									Probabilistic model
								</div>
								<div class="block-content">
									<div style="position:relative; width:400px; height:100px; margin:0 auto;">
										<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="0"> $$ x \sim ? $$ </div>
										<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="1"> $$ x \sim \mathcal{N}(z, \Sigma) \quad z \sim ? $$<br>latent $z$ is a denoised galaxy image</div>
										<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="2"> $$ x \sim \mathcal{N}( \mathbf{P} z, \Sigma) \quad z \sim ?$$<br>latent $z$ is a super-resolved and denoised
											galaxy image</div>
										<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="3"> $$ x \sim \mathcal{N}( \mathbf{P} (\Pi \ast z), \Sigma) \quad z \sim ? $$<br>latent $z$ is a deconvolved,
											super-resolved, and denoised galaxy image </div>
										<div class="plain fragment " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="4"> $$ x \sim \mathcal{N}( \mathbf{P} (\Pi \ast g_\theta(z)), \Sigma) \quad z \sim \mathcal{N}(0, \mathbf{I}) $$ <br>latent $z$
											is a Gaussian sample<br> <b class="alert"> $\theta$ are parameters of the model</b> </div>
									</div>
									<br>
									<br>
									<br>
								</div>
							</div>
						</div>
					</div>
					<div class="fragment"> $\Longrightarrow$ <b class="alert"> Decouples the morphology model from the observing conditions</b>.</div>
				</section>

				<section>
					<h3 class="slide-title">Bayesian Inference a.k.a. Uncertainty Quantification</h3>
					<div class="container">
						<div class="col">
							<img data-src="assets/pgm.png" class="plain" style="height: 250px;"></img>
						</div>
						<div class="col">
							The Bayesian view of the problem:
							$$ p(z | x ) \propto p_\theta(x | z, \Sigma, \mathbf{\Pi}) p(z)$$
							where:
							<br>
							<ul>
								<li>$p( z | x )$ is the <b class="alert">posterior</b></li>
								<li>$p( x | z )$ is the data likelihood, <b class="alert">contains the physics</b></li>
								<li>$p( z )$ is the <b>prior</b> </li>
							</ul>
						</div>
					</div>

					<div class="container">
						<div class="col">
							<div style="position:relative; width:200px; height:200px; margin:0 auto;">
								<img class="plain fragment current-visible" data-src="assets/cosmos_gal_ground.png" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="0" />
								<img class="plain fragment" data-src="assets/cosmos_gal.png" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="1" />
							</div>
							<div class="container" style="position:relative; width:200px; height:50px; margin:0 auto;">
								<div class='col fragment current-visible' data-fragment-index='0' style="position:absolute;top:0;left:0;width:200px;"> Data<br> $x_n$</div>
								<div class='col fragment' data-fragment-index='1' style="position:absolute;top:0;left:0;width:200px;"> Truth<br> $x_0$ </div>
							</div>
							<br>
						</div>

						<div class="col fragment" data-fragment-index='0'>
							<div style="position:relative; width:200px; height:200px; margin:0 auto;">
								<div><video data-autoplay data-loop data-src="assets/rec_samples.mp4" type="video/mp4" style="height: 200px;" />
								</div>
							</div>
							<div>Posterior samples<br> $g_\theta(z)$</div>
						</div>

						<div class="col">
							<div style="position:relative; width:200px; height:200px; margin:0 auto;">
								<div><video class="fragment current-visible" data-autoplay data-loop data-src="assets/rec_lsst.mp4" type="video/mp4" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="0" /></div>
								<img class="plain fragment " data-src="assets/rec_median.png" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="1" />
							</div>

							<div class="container" style="position:relative; width:200px; height:50px; margin:0 auto;">
								<div class='col fragment current-visible' data-fragment-index='0' style="position:absolute;top:0;left:0;width:200px;"> <br> $\mathbf{P} (\Pi \ast g_\theta(z))$</div>
								<div class='col fragment' data-fragment-index='1' style="position:absolute;top:0;left:0;width:200px;"> Median </div>
							</div>
						</div>

						<div class="col">
							<div style="position:relative; width:200px; height:200px; margin:0 auto;">
								<div><video class="fragment current-visible" data-autoplay data-loop data-src="assets/res_lsst.mp4" type="video/mp4" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="0" /></div>
								<img class="plain fragment " data-src="assets/rec_std.png" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="1" />
							</div>

							<div class="container" style="position:relative; width:200px; height:50px; margin:0 auto;">
								<div class='col fragment current-visible' data-fragment-index='0' style="position:absolute;top:0;left:0;width:200px;"> Data residuals <br> $x_n - \mathbf{P} (\Pi \ast g_\theta(z))$</div>
								<div class='col fragment' data-fragment-index='1' style="position:absolute;top:0;left:0;width:200px;"> Standard Deviation </div>
							</div>
						</div>
					</div>
					<div class="fragment"> $\Longrightarrow$ <b class="alert">Uncertainties are fully captured by the posterior</b>.</div>
				</section>
			</section>

			<section>
				<h3 class="slide-title">How to perform efficient posterior inference?</h3>
				<div class="container">

					<div class="col">
						<img class="plain " data-src="assets/cosmos_gal_ground.png" style="height:200px;" />
					</div>

					<div class="col">
						<div style="height:200px"><video data-autoplay data-loop data-src="assets/rec_samples.mp4" type="video/mp4" style="height: 200px;" />
						</div>
					</div>
					<hr style="width: 2px; height: 200px; background: white; border: none;" />
					<div class="col">
						<img class="fragment plain" data-fragment-index="3" data-src="assets/deep_uq_4.png" style="height:200px" />
					</div>

					<div class="col">
						<img class="fragment plain" data-fragment-index="3" data-src="assets/deep_uq_contours.png" style="height:200px" />
					</div>

					<div class="col">
						<img class="fragment plain" data-fragment-index="3" data-src="assets/deep_uq_recs.png" style="height:200px" />
					</div>
				</div>

				<div style="float:right; font-size: 20px" class="fragment" data-fragment-index="3"><a href="https://arxiv.org/abs/1910.10046">(Böhm, Lanusse, Seljak 2019)</a></div>
				<ul>
					<li class="fragment" data-fragment-index="1">Posterior fitting by <b class="alert">Variational Inference</b>
						<br>
						$$ \mathrm{ELBO} = - \mathbb{D}_{KL}\left( q_\phi(z) \parallel p(z) \right) \quad + \quad \mathbb{E}_{z \sim q_{\phi}} \left[ \log p_\theta(x_n | z, \Sigma_n, \Pi_n) \right]$$
					</li>

					<li class="fragment" data-fragment-index="3">Posterior fitting by <b class="alert">$EL_{2}O$</b> <br>
						$$EL_2O = \arg \min_\theta \mathbb{E}_{z \sim p^{\prime}} \sum_i \alpha_i \parallel \nabla_{z}^n \ln q_\theta(z) - \nabla_{z}^{n} \ln p(z | x_n, \Sigma_n, \Pi_n) \parallel_2^2$$See <a href="https://arxiv.org/abs/1901.04454"> (Seljak & Yu,
							2019)</a> for more details.
					</li>
					<br>
					<li class="fragment" data-fragment-index="5">Or your favorite method...</li>
				</ul>
			</section>

			<section>
				<h3 class="slide-title">Conclusion</h3>
				<br>
				<br>
				<ul>
					<li> Generative Models provide a data-driven way to learn a complex
						non-linear representation of the data.
					</li>

					<br><br>

					<li> Can be more powerful than sparsity, but requires a lot of data
						to train.
					</li>

					<br><br>

					<li> Modern inference algorithm allow for sampling from the full posterior
						of the problem for uncertainty quantification.
					</li>
				</ul>

			</section>

		</div>
	</div>

	<style>
		/* .reveal .slides {
			border: 5px solid red;
			min-height: 100%;
			width: 128mm;
			height: 96mm;
		} */

		.reveal .block {
			background-color: #191919;
			margin-left: 20px;
			margin-right: 20px;
			text-align: left;
			padding-bottom: 0.1em;
		}

		.reveal .block-title {
			background-color: #333333;
			padding: 8px 35px 8px 14px;
			color: #FFAA7F;
			font-weight: bold;
		}

		.reveal .block-content {
			padding: 8px 35px 8px 14px;
		}

		.reveal .slide-title {
			border-left: 5px solid white;
			text-align: left;
			margin-left: 20px;
			padding-left: 20px;
		}

		.reveal .alert {
			color: #FFAA7F;
			font-weight: bold;
		}

		.reveal .inverted {
			filter: invert(100%);
		}

		/*
	/* .reveal .alert {
	padding:8px 35px 8px 14px; margin-bottom:18px;
	text-shadow:0 1px 0 rgba(255,255,255,1);
	border:5px solid #FFAA7F;
	-webkit-border-radius: 14px; -moz-border-radius: 14px;
	border-radius:14px
	background-position: 10px 10px;
	background-repeat: no-repeat;
	background-size: 38px;
	padding-left: 30px; /* 55px; if icon
	}
	.reveal .alert-block {padding-top:14px; padding-bottom:14px}
	.reveal .alert-block > p, .alert-block > ul {margin-bottom:1em}
	/*.reveal .alert li {margin-top: 1em}
	.reveal .alert-block p+p {margin-top:5px} */
	</style>


	<script src="reveal.js/dist/reveal.js"></script>
	<script src="reveal.js/plugin/notes/notes.js"></script>
	<script src="reveal.js/plugin/markdown/markdown.js"></script>
	<script src="reveal.js/plugin/highlight/highlight.js"></script>
	<script src="reveal.js/plugin/math/math.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			controls: false,

			//center: false,
			hash: true,

			// Visibility rule for backwards navigation arrows; "faded", "hidden"
			// or "visible"
			controlsBackArrows: 'hidden',

			// Display a presentation progress bar
			progress: true,

			// Display the page number of the current slide
			slideNumber: true,

			transition: 'slide', // none/fade/slide/convex/concave/zoom

			// The "normal" size of the presentation, aspect ratio will be preserved
			// when the presentation is scaled to fit different resolutions. Can be
			// specified using percentage units.
			width: 1280,
			height: 720,

			// Factor of the display size that should remain empty around the content
			margin: 0.1,

			// Bounds for smallest/largest possible scale to apply to content
			minScale: 0.2,
			maxScale: 1.5,


			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath],

			dependencies: [{
					src: 'reveal.js/plugin/markdown/marked.js'
				},
				{
					src: 'reveal.js/plugin/markdown/markdown.js'
				},
				{
					src: 'reveal.js/plugin/notes/notes.js',
					async: true
				},
				{
					src: 'reveal.js/plugin/math/math.js',
					async: true
				},
				{
					src: 'reveal.js/plugin/reveal.js-d3/reveald3.js'
				},
				{
					src: 'reveal.js/plugin/reveal.js-plugins/chart/Chart.min.js'
				},
				{
					src: 'reveal.js/plugin/reveal.js-plugins/chart/csv2chart.js'
				},
				{
					src: 'reveal.js/plugin/highlight/highlight.js',
					async: true
				},
			]

		});
	</script>
</body>

</html>