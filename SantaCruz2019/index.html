<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Machine Learning for Modern Cosmological Surveys</title>

		<meta name="description" content="SantaCruz 2019">
		<meta name="author" content="Francois Lanusse">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<link rel="stylesheet" href="reveal.js/css/reset.css">
		<link rel="stylesheet" href="reveal.js/css/reveal.css">
		<link rel="stylesheet" href="reveal.js/css/theme/darkenergy.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="reveal.js/lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
			<!-- Any section element inside of this container is displayed as a slide -->

							<section data-background-image="assets/lsst_stills_0009_crop.jpg" >

									<div class="container">
										<div class="title" style="border-radius: 20px; background-color:rgba(0, 0, 0, 0.4);">
											<h1>Machine Learning for Modern Cosmological Surveys</h1>
											<h3>UC Santa Cruz, July 29th, 2019</h3>
									</div>
								</div>

								<hr>
								<div style="border-radius: 20px; background-color:rgba(0, 0, 0, 0);">
										<div class="container" >
												<div class="col">
													<div align="left" style="margin-left: 20px;">
													<br>
													<h3>Fran√ßois Lanusse</h3>
													<p>	University of California, Berkeley</p>

													<img src="assets/logo_bccp.png" class="plain" height="100"></img>
													<br>

													</div>
												</div>
												<div class="col">
													<br>
													<br>
													<img src="assets/bids-logo2.png" class="plain" height="150"></img>
													<img src="assets/desc-logo-inv.png" class="plain" height="200"></img>
												</div>
											</div>
									</div>
								</section>

								<section data-background-image="assets/WMAP_timeline_large.jpg">
									<h3 class='slide-title' style="position:absolute;top:0;"> the $\Lambda$CDM view of the Universe </h3>
<br>	<br>
									<div class="container">
										<div class="col" style="flex: 0 0 40em;">

										</div>
										<div class="col">

									  <img class="plain" data-src="assets/Euclid.png" style="width: 300px"/>

									  <img class="plain" data-src="assets/wfirstlogo.png" style="width: 300px"/>

									  <img class="plain" data-src="assets/LSST_web_black.png" style="width: 300px"/>
										</div>
									</div>
											<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>
								</section>


								<section>
								<section data-background-video="assets/animation-day-to-night.mov" data-background-video-muted>
									<h3 class='slide-title'>the Large Synoptic Survey Telescope</h3>
								<div class="container">
								<div class="col">
									<ul>
										<li class="fragment fade-up"> 1000 images each night, 15 TB/night for 10 years</li>
										<br>
										<li class="fragment fade-up"> 18,000 square degrees, observed once every few days</li>
										<br>
										<li class="fragment fade-up"> Tens of billions of objects, each one observed $\sim1000$ times</li>
									</ul>
									<br >
									<!-- <p class="fragment fade-up"> $\Longrightarrow$ Incredible potential for discovery, along with <b>unprecedented challenges</b >.</p> -->
								</div>

							 <div class="col">
									<video class="fragment fade-up"  data-fragment-index="1" data-autoplay data-src="assets/obsim.mp4" type="video/mp4" />
							 </div>
						 </div>

						 </section>
						 			<section data-transition="fade-in fade-out" data-background="assets/gal_sdss.png" data-vertical-align-top>
										<p>Previous generation survey: SDSS</p>
										<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>
										<br>	<br>	<br>	<br>	<br>	<br>	<br>
						 								<div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
						 			</section>
						 			<section data-transition="fade-in fade-out" data-background="assets/gal_des.png" data-vertical-align-top>
										<p>Current generation survey: DES</p>
										<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>
										<br>	<br>	<br>	<br>	<br>	<br>	<br>
						 								<div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
						 			</section>
									<section data-transition="fade-in fade-out" data-background="assets/gal_hsc.png" data-vertical-align-top>
										<p>LSST precursor survey: HSC</p>

										<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>
										<br>	<br>	<br>	<br>	<br>	<br>	<br>
						 								<div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
					 			</section>
								<section>
								<h3  class='slide-title'>The challenges of modern surveys</h3>
								$\Longrightarrow$  Modern surveys will provide <b>large volumes</b> of <b>high quality</b> data
								<br>

										<br>
								<div class="container">
										<div class="col">

											<div class="block fragment">
												<div class="block-title">
													A Blessing
												</div>
												<div class="block-content">
													<ul>
														<li>Unprecedented statistical power
														</li>
														<br>
														<li>Great potential for new discoveries
														</li>
													</ul>
											</div>
										</div>

										<br>
										<div class="block fragment">
											<div class="block-title">
												A Curse
											</div>
											<div class="block-content">
												<ul>
													<li> Existing methods are reaching their limits at every
														step of the science analysis
													</li>
													<br>
													<li>Control of systematic uncertainties becomes paramount
													</li>
												</ul>
										</div>
									</div>

									</div>
										<div class="col">
											LSST forecast on dark energy parameters
											<img class="plain" data-src="assets/LSST_forecast_Y10.png" style="height :450px"/>
										</div>
								</div>
								<div class="fragment">
								$\Longrightarrow$ Dire need for <b class="alert">novel analysis techniques</b> to fully realize the potential of modern surveys.
							</div>
								</section>
							</section>

							<section>
								<h3  class='slide-title'>Outline of this talk</h3>
								<br>
								<br>
								<h3> Where can Deep Learning help address the challenges of modern surveys ?</h4>
								<br>
								<br>
								<ul>
									<li class="fragment grow">Low level image processing</li>
									<br>
									<br>
									<li  class="fragment grow">Fast emulation of complex simulations</li>
									<br>
									<br>
									<li  class="fragment grow">Probabilistic inference</li>
								</ul>
								<br>
								<br>
								<br>
								<br>
							</section>

							<section>
								<h2> Hybrid physics-ML models for image inverse problems</h2>
							</section>

							<section>
							<section data-background="assets/gal_hsc.png">

							</section>
							 				<section>
							 					<h3 class="slide-title">The challenge of galaxy blending</h3>
														<div class="container">
																<div class="col">
																	<div style="position:relative; width:480px; height:500px; margin:0 auto;">
																		<img class="fragment current-visible plain"  data-src="assets/hsc_deblending_success.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
																		<img class="fragment plain" data-src="assets/hsc_shredded.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
																	</div>
																	<div class="fragment" data-fragment-index="0" style="float:left; font-size: 20px">Bosch et al. 2017</div>
																</div>
																<div class="col">
																<ul>
																	<li class="fragment fade-up" data-fragment-index="0"> In HSC over 60% of all galaxies are blended</li>
																	<br>
																	<li class="fragment fade-up" data-fragment-index="0"> Important impact on our main cosmological probes</li>
																	<br>
																	<li class="fragment fade-up" data-fragment-index="1"> Current generation of deblenders does not meet our target requirements</li>
																	<br>
																	<ul class="fragment fade-up" data-fragment-index="2">
																		<li> Existing methods rely on simple assumptions about galaxy profiles, like <i>symmetry</i> or <i>monotonicity</i></li>
																	</ul>
																</ul>
																</div>
														</div>

														<div class="fragment fade-up"data-fragment-index="3" >
															Deblending is an ill-posed inverse problem, akin to <i>Blind Source Separation</i>. The is no <b>single solution</b>.<br>
															$\Longrightarrow$ Intuitively, the key will to leverage an understanding of how individual <i>galaxies look like</i>.
														</div>
							 				</section>
											</section>

											<section>
												<section>
												<h3 class="slide-title">Deep Learning applied to deblending (Reiman & Gohre 2018)</h3>
															<div>
															<img class="plain" data-src="assets/Reiman2018_1.png" />
																Branched GAN model for deblending
															</div>

														<div class="block fragment">
															<div class="block-title">
																The issue with <i>black-box</i> models
															</div>
															<div class="block-content">
																<ul>
																	<li> No explicit control of noise, PSF, depth, number of sources.
																			<ul>
																				<li> Model would have to be retrained for all observing configurations
																				</li>
																			</ul>
																	</li>
																	<br>
																	<li> No guarantees on the network output (e.g. flux preservation, artifacts)
																	</li>
																</ul>
														</div>
													</div>
												</section>

												<section>
															<img class="plain" data-src="assets/Reiman2018_2.png"/>
												</section>
											</section>

											<section>
											<section>
												<h3 class="slide-title">Linear inverse problems</h3>

												$\boxed{y =  \mathbf{A}x + n}$
												<br>
												<br>
												$\mathbf{A}$ is known and encodes our physical understanding of the problem.
												<span class="fragment"><br>$\Longrightarrow$ When non-invertible or ill-conditioned, the inverse problem is ill-posed with no unique solution $x$</span>
												<div class="container fragment fade-up">
														<div class="col">
															<img data-src="assets/pluto_smooth.png" class="plain"></img>
															Deconvolution
														</div>
														<div class="col">
															<img data-src="assets/pluto_missing.png" class="plain"></img>
															Inpainting
														</div>
														<div class="col">
															<img data-src="assets/plutoNoise.png" class="plain"></img>
															Denoising
														</div>
												</div>

											</section>

											<section data-vertical-align-top>
												$\boxed{y =  \mathbf{A}x + n}$
												<br>
												<br>
												The Bayesian view of the problem:
												<br>
												<br>
												$$ p(x | y) \propto p(y | x) \ p(x) $$
												<br>

												<ul>
													<li class="fragment fade-up">$p(y | x)$ is the data likelihood, which <b>contains the physics</b><br>
													</li>
													<br>
													<li class="fragment fade-up">$p(x)$ is our prior knowledge on the solution.</li>
												</ul>
												<br>
												<br>
												<div class="fragment fade-up">
												With these concepts in hand, we want to estimate the Maximum A Posteriori solution:
												<br>
												<br>
												$$\hat{x} = \arg\max\limits_x \ \log p(y \ | \ x)  + \log p(x)$$
												<br>
												For instance, if $n$ is Gaussian, $\hat{x} = \arg\max\limits_x \ \frac{1}{2} \parallel y - \mathbf{A} x \parallel_{\mathbf{\Sigma}}^2 + \log p(x)$
												</div>
												<br>
												<div class="fragment fade-up">
													<h3>How do you choose the prior ?</h3>
												</div>
											</section>

											<section>
												<h3 class="slide-title"> Classical examples of signal priors </h3>
													<div class="container">
														<div class="col">
															Sparse
															<img data-src="assets/wavelet.png" height="400" class="plain"></img><br>
															$$ \log p(x) = \parallel \mathbf{W} x \parallel_1 $$
														</div>
														<div class="col">
															Gaussian
															<img data-src="assets/zknj8.jpg" height="400" class="plain"></img>
															$$ \log p(x) = x^t \mathbf{\Sigma^{-1}} x $$
														</div>
														<div class="col">
															Total Variation
															<img data-src="assets/shepp-Logan.ppm" class="plain"></img>
															$$ \log p(x) = \parallel \nabla x \parallel_1 $$

														</div>
												</div>
											</section>

											<section data-background="assets/hsc_screen.png">
													<h2>But what about this?</h2>

											</section>
										</section>

										<section class="inverted" data-background="#000">
											<h2>
											Can we use Deep Learning to learn the prior from data?</h2>
										</section>


										<section>
											<h3 class="slide-title"> The evolution of generative models </h3>

											<br> <br> <br>
											<div class='container'>
												<div class='col'>
													<div style="position:relative; width:480px; height:300px; margin:0 auto;">
														<img class="fragment current-visible plain" data-src="assets/DBN.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
														<img class="fragment current-visible plain" data-src="assets/vae_faces.jpg" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
														<img class="fragment current-visible plain" data-src="assets/gan-samples-1.png" style="position:absolute;top:0;left:0;" data-fragment-index="2" />
														<img class="fragment plain" data-src="assets/karras2017.png" style="position:absolute;top:0;left:0;" data-fragment-index="3" />
													</div>
												</div>

										<div class='col'>
											<ul>
												<li class="fragment" data-fragment-index="0"> Deep Belief Network <br> (Hinton et al. 2006) </li>
												<br>
												<li class="fragment" data-fragment-index="1"> Variational AutoEncoder <br> (Kingma & Welling 2014) </li>
												<br>
												<li class="fragment" data-fragment-index="2"> Generative Adversarial Network <br> (Goodfellow et al. 2014)</li>
												<br>
												<li class="fragment" data-fragment-index="3"> Wasserstein GAN <br> (Arjovsky et al. 2017) </li>
											</ul>
											</div>
										</div>
											<br> <br> <br>
										</section>

										<section>
											<h3 class="slide-title"> A visual Turing test </h3>
											<div class="container">
													<div class="col">
														<img data-src="assets/samples_pixel_cnn.png" class="plain" style="height: 500px;" ></img>
														<br>
														<div class="fragment fade-up" data-fragment-index="0"> Fake PixelCNN samples </div>
													</div>
													<div class="col">
														<img data-src="assets/sdss5.png" class="plain"  style="height: 500px;" ></img>
														<br>
														<div class="fragment fade-up" data-fragment-index="0"> Real SDSS </div>
													</div>
											</div>
										</section>

										<section>
											<h3 class="slide-title" >A deblending toy example</h3>
											<div class="container">
											<div class="col">
													<div class="fig-container" data-file="dgm_prior.html" data-style="height: 550px;"></div>
													<br>
													Try me out at: <a href="https://eiffl.github.io/DeepPriors">https://eiffl.github.io/DeepPriors</a>
											</div>

										 <div class="col">
											 <ul>
												 <li>Assume a blend with two components $x_1$ and $x_2$ <br> $x_1 + x_2$ must match the data $y$</li>
												 <br>
												 <li>Each component of the blend should lie on the "realistic galaxy manifold", symbolized by the two-moons distribution.</li>
											 </ul>
											 <p> We are solving: </p>
												 $\arg \max - \frac{1}{2} \parallel {\color{Orchid} y} - {\color{red} \sum_{\color{red} i} {\color{red} x}_{\color{red} i}} \parallel_2^2 + \log p({\color{SkyBlue} x_{\color{SkyBlue} 1}}) + \log p({\color{GreenYellow} x_{\color{GreenYellow} 2}}) $
												 <br>
												 <br>
												 This can be done by gradient descent as long  as one has access to $\frac{\color{orange} d \color{orange}\log \color{orange}p\color{orange}(\color{orange}x\color{orange})}{\color{orange} d \color{orange}x}$.
									 	 </div>
								 </div>
									</section>
										<section data-vertical-align-top>
											<h3 class="slide-title" >Not all generative models are created equal</h3>
														<img data-src="assets/generative_models_table.png" class="plain"></img>
									 						<div style="float:right; font-size: 20px">Grathwohl et al. 2018</div>
												<br>
												<br>
											<ul>
												<li> GANs and VAEs are very common and successfull but do not fit our purposes.</li>
												<br>
												<li> We need a model which can provide explicitly $\log p(x)$.</li>
												<br>
											</ul>
										</section>

										<section>
											<h3  class="slide-title">PixelCNN: Likelihood-based Autoregressive generative model</h3>
											<div class="container">
											<div class="col">
													Models the probability $p(x)$ of an image $x$ as:
													$$ p_{\theta}(x) = \prod_{i=0}^{n} p_{\theta}(x_i | x_{i-1} \ldots x_0) $$
													<ul>
															<li>Some of the best log-likelihoods on the market.</li>
															<li>Extremely stable during training.</li>
															<li>Slow to sample from.</li>
													</ul>
													<br>
													<br>

													<div class="fragment fade-up">
														<img data-src="assets/speedup.gif" class="plain"></img>
														<br>
										 				<div style="float:left; font-size: 20px">Ramachandran et al. 2017</div>
													</div>

											</div>

											<div class="col">
													<img data-src="assets/pixel_cnn_conv.png" class="plain"></img>
									 				<div style="float:right; font-size: 20px">van den Oord et al. 2016</div>
											</div>
										 </div>
										</section>

										<section>
											<h3 class="slide-title"> The Scarlet algorithm: deblending as an optimization problem</h3>
													<div style="float:right; font-size: 20px">Melchior et al. 2018</div>

													<br>
													$$ \mathcal{L} = \frac{1}{2} \parallel \mathbf{\Sigma}^{-1/2} (\ Y - P \ast A S \ ) \parallel_2^2 - \sum_{i=1}^K \log p_{\theta}(S_i) + \sum_{i=1}^K g_i(A_i) +  \sum_{i=1}^K f_i(S_i)$$

											<div class="container">
											<div class="col">
													<img data-src="assets/scarlet_data.png" height=450 class="plain"></img>
											</div>

											<div class="col">

												Where for a $K$ component blend:
												<br>
													<ul>
													<li>$P$ is the convolution with the instrumental response</li>
													<br>
													<li>$A_i$ are channel-wise galaxy SEDs, $S_i$ are the morphology models</li>
													<br>
													<li>$\mathbf{\Sigma}$ is the noise covariance</li>
													<br>
													<li>$\log p_\theta$ is a PixelCNN prior</li>
													<br>
													<li>$f_i$ and $g_i$ are arbitrary additional non-smooth consraints, e.g. positivity, monotonicity...</li>
													</ul>
											</div>
										</div>

										<br>
										<br>
										<span class="fragment fade-up">$\Longrightarrow$ Explicit physical modeling of the observed sky</span>
										</section>

										 <section>
											<h3  class="slide-title">Training the morphology prior</h3>

											<div class="container">
												<div class="col">
													<img data-src="assets/cosmos_training.png" height=450 class="plain"></img>
													<div> Postage stamps of isolated COSMOS galaxies used for training, at WFIRST resolution and fixed fiducial PSF</div>
											</div>

											<div class="col">
											<div class="container fragment fade-in">
												<div class="col">
													isolated galaxy
												<img data-src="assets/gal_1.png" class="plain"></img>
												<span> $\log p_\theta(x) = 3293.7$ </span>
											</div>

												<div class="col">
													artificial blend
												<img data-src="assets/gal_2.png" class="plain"></img>
												<span> $\log p_\theta(x) = 3100.5 $ </span>
											</div>
												</div>
											</div>
										</section>

										<section>
											<section>
											<h3 class="slide-title">Scarlet in action</h3>

											<div class="container">
												<div class="col">
													Input blend
												<div style="position:relative; width:480px; height:480px; margin:0 auto;">
												<img data-src="assets/scar_input.png" class="plain"></img>
											</div>
												</div>

											<div class="col">
												<span class="fragment" data-fragment-index="0">Solution</span>
												<div style="position:relative; width:480px; height:480px; margin:0 auto;">
														  <img class="fragment current-visible plain" data-src="assets/old_rec.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
														  <img class="fragment  plain" data-src="assets/pix_rec.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
												</div>
											</div>

											<div class="col">
												<span class="fragment" data-fragment-index="0">Residuals</span>
												<div style="position:relative; width:480px; height:480px; margin:0 auto;">
														  <img class="fragment current-visible plain" data-src="assets/old_res.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
														  <img class="fragment  plain" data-src="assets/pix_res.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
												</div>
											</div>
											</div>

											<ul>
													<li class="fragment fade-up" data-fragment-index="0">Classic priors (monotonicity, symmetry).</li>
													<br>

													<li class="fragment fade-up" data-fragment-index="1">Deep Morphology prior.</li>
											</ul>

										</section>
										<section>
											<div class="container">
												<div class="col">
													True Galaxy
												<img data-src="assets/true_input.png" class="plain"></img>
											</div>

											<div class="col">
												Deep Morphology Prior Solution

															<img class=" plain" data-src="assets/pix_rec2.png"  />

											</div>

											<div class="col">
												Monotonicity + Symmetry Solution
															<img class=" plain" data-src="assets/scar_rec2.png" />
												</div>
											</div>
										</section>
										</section>


										<section>
											<h3 class="slide-title"> takeaway message</h3>

											<br> <br>

											<div class="block ">
												<div class="block-title">
													Deep Learning for Low Level Processing
												</div>
												<div class="block-content">
													<ul>
														<li class="fragment"> An example of Deep Learning allowing us to handle
															the <b class="alert">volume and complexity</b> at the image level</li>
														<br>

														<li class="fragment">Likelihood-based Deep Generative Models are an ideal tool to <b>complement physical modeling</b><br> $\Longrightarrow$ They interface directly with our existing Bayesian machinery for solving inverse problems.</li>
													</ul>
												</div>
											</div>

											<div class="fragment">
												Other examples:
												<div class="container">
													<div class="col">
														<img class="plain" data-src="assets/huang2019_small.png"/>
														(Huang et al. 2019) finding strong gravitational lenses with CMU DeepLens (Lanusse et al. 2018)
													</div>
													<div class="col">
														<img class="plain" data-src="assets/vae_samples2.png"/>
														Generative models for galaxy morphology (Ravanbakhsh, Lanusse, et al. 2017)
													</div>
												</div>
											</div>

										</section>


										<section>
												<h1>Graph Convolutional Networks for Modeling Galaxy Properties</h1>
										</section>

										 <section data-background-image="assets/gravitational-lensing-diagram.jpg">
											 <div class="fragment fade-up">
												 <img class="plain" data-src="assets/great.jpg">
											 </div>
										 </section>

											<section>
											 	 <section>
												 <h3 class="slide-title" > Intrinsic alignments of galaxies </h3>
												 <div class="container">
													 <div class="col">
														 	<img class="plain" data-src="assets/lensing_schematic.jpg"/>
															$$ \underbrace{\epsilon}_{\tiny \mbox{observed ellipticity}} = \underbrace{\epsilon_i}_{\tiny \mbox{intrinsic ellipticity}} + \underbrace{\gamma}_{\tiny \mbox{lensing}}$$
															<br>
															<p class="fragment highlight-red" data-fragment-index="1"> assuming $< \epsilon_i \epsilon_i^\prime > = 0$ </p>
													 </div>

													 <div class="col">
														 <div class="fragment fade-up" data-fragment-index="1">
														 	<img class="plain" data-src="assets/kirk2015.png " style="height: 500px;"/><br>
															<div style="float:right; font-size: 20px">Kirk et al. (2015)</div>
														</div>
													 </div>
												 </div>
											 	</section>

												<section>
													<div class="container">
														<div class="col">
															<img class="plain" data-src="assets/IA.png">
															<div style="float:left; font-size: 20px">Kiessling et al. (2015)</div>
														</div>

														<div class="col">
														 <div class="fragment fade-up" data-fragment-index="1">
															<img class="plain" data-src="assets/ed.png" style="height: 500px;">
															<div style="float:right; font-size: 20px">Tenneti et al. (2015)</div>
														</div>
														</div>
													</div>
														<ul>
																<li> Tidal interactions with local gravitational potential
																	<br>
																	<br>
																<li class="fragment fade-up" data-fragment-index="1"> Much more complicated in details, no single model for all galaxy types, impacted by baryonic physics <br>
																	$\Longrightarrow$ study requires <b>expensive hydrodynamical simulations</b>
														</ul>
												</section>

												<section data-background-video="assets/illustris_movie_cube_sub_frame.mp4">
													<div class="fragment fade-up">
														<img data-src="assets/IAhydro.png" style="height: 500px;"><br>
														<div style="float:right; font-size: 20px">Kiessling et al. (2015)</div>
													</div>
												</section>
											</section>

											<section class="inverted" data-background="#000">
												<h2>
													How to produce mock galaxy catalogs on large cosmological
													volumes with realistic alignments ?</h2>
											</section>

											<section>
												<h3 class="slide-title">Inpainting galaxy orientations in simulations </h3>
												<div class="container">
													<div class="col">
														<img class="plain" data-src="assets/mb2_z0_0204a.png"><br>
														Massive Black II
													</div>

													<div class="col">
													 <div class="fragment fade-up" data-fragment-index="1">
														<img class="plain" data-src="assets/dmo_z0_0204a.png"><br>
														Dark Matter Only
													</div>
													</div>
												</div>
												<br>
												<span class="fragment" data-fragment-index=1>$gal \sim$</span > $ p( \vec{a}_{3D} \ | \ x_{DM}, M_{DM}, \ldots ) $
													<br>
												<br>
												<span class="fragment">$\Longrightarrow$ We propose a deep generative model on graphs</span>
											</section>

											<section class="fig-container" data-file="graph.html"> <!--data-background-iframe="graph.html" data-background-interactive data-transition="none"> -->
												<h3 class="slide-title" style="background-color:rgba(0, 0, 0, 0.5);position: fixed;  top: 0 !important;">Modelling the cosmic web as a graph</h3>

												<br> <br> <br> <br> <br>
												<br> <br> <br> <br> <br>
												<br> <br> <br> <br> <br>
												<br> <br> <br> <br> <br>
												<div style="float:right; font-size: 20px; position: fixed; bottom: 0;">Adapted from <a href="http://cosmicweb.kimalbrecht.com/">the network behind the cosmic web</a> (credit: Kim Albrecht)</div>
											</section>

											<section>
												<section>
													<h3 class="slide-title">A few words about spectral graph theory</h3>
													Consider a weighted undirected graph $\mathcal{G} = (\mathcal{V}, \mathcal{E})$
													<br>with N nodes $v_i \in \mathcal{V}$ and edges $(v_i, v_j) \in \mathcal{E}$.

												<br><br>
												<div class="container">
													<div class="col" >
														<img class="plain" data-src="assets/small_graph.png" style="width: 75%;"/>
													</div>

													<div class="col">
														<ul>
														<li class="fragment fade-in"> Adjacency matrix: $A = \{ w_{ij} \}_{i,j\in [1, N]}$  </li>
														<br>
														<li class="fragment fade-in"> Degree matrix: $D_{ii} = \sum_j A_{ij} $ </li>
														<br>
														<li class="fragment fade-in"> <b>Normalized graph Laplacian</b>:
															$$\mathbf{L} = \mathbf{I}_N - D^{- \frac{1}{2}} A D^{- \frac{1}{2}}$$
														</li>
													</ul>
													</div>
												</div>
												<br>

												<span  class="fragment fade-in">$\mathbf{L}$ is positive-semidefinite, admits the following eigen-decomposition:
							$$L = U \ \Lambda \ U^T \quad \mbox{with $\mathbf{\Lambda} = \mathrm{diag}(\lambda_0, \cdots, \lambda_N)$}$$</span>
												</section>

												<section>
													<h3  class="slide-title">Graph Fourier Transform and Spectral Convolutions</h3>
							The graph Fourier transform of a signal $f: \mathcal{V} \mapsto \mathbb{R}$ is defined as:
							$$ \hat{f} = \mathbf{U}^T f \quad \mbox{with $\hat{f} = \mathrm{diag}(\hat{f}_0, \cdots, \hat{f}_n)$}$$
							<img class="plain" data-src="assets/eigenvectors.png"/>
<br>
							<span class="fragment fade-in">The convolution of a signals $f$ with a filter $g_\theta$ can be defined as $$ g_\theta \star f = \mathbf{U} \  \hat{g}_\theta \  \mathbf{U}^T f $$</span>

								<ul>
									<li class="fragment fade-in">If we can compute convolutions of a signal with a parameterized filter, we can <b>extend convolutional neural networks to graphs</b>.</li>
									<br>
									<li class="fragment fade-in">Spectral graph convolutions are too expensive, $\mathcal{O}(N^2)$ operations</li>
								</ul>

										</section>
											</section>

											<section>
												<section>
													<h3 class="slide-title">Graph Convolutional Network</h3>
							Filters can be approximated by a truncated Chebyshev polynomials expansion
								$$ g_{\theta}(\Lambda) \approx  g_{\theta^\prime}(\Lambda) = \sum_{k=0}^K \theta_k^{\prime} T_k ( \tilde{\Lambda}) \quad \mbox{ with $\tilde{\Lambda} = \frac{2}{\lambda_\mathrm{max}} \ \Lambda - \mathbf{I}_N$}$$
							<div style="float:right; font-size: 20px">Hammond et al. (2011)</div>

							 <ul>
								<li> Convolutions with polynomial filters <b>by-pass the graph Fourier transform</b> thanks to $U \Lambda^k U^T = (U \Lambda U^T)^k$:
								$$ g_{\theta^\prime} \star f = U \ \sum_{k=0}^K \theta_k^{\prime} T_k ( \tilde{\Lambda}) \ U^T f =  \sum_{k=0}^K \theta_k^{\prime} T_k ( \tilde{L}) f$$
							</li>
							<br>
								<li>Recurrence relation of Chebyshev polynomials allows for efficient computation (only requires $K$ Laplacian multiplications)</li>
							</ul>
										</section>

										<section>
											<ul>
												<li>Defferrard et al. (2016); Kipf & Welling (2017) suggest approximating the convolution with a polynomial expansion to $K=1$:
														$$ g_{\theta^\prime} \star f  = \theta_0^\prime f - \theta_1^\prime \ D^{- \frac{1}{2}} A D^{- \frac{1}{2}} \ f $$
												</li>
											</ul>
											<br>
											<span class="fragment fade-up" data-fragment-index="0">$\Longrightarrow$ Tractable graph convolutions using an approximation restricted to first neighbors</span>
											<br>
											<img data-src="assets/gcn_web.png" class="plain fragment fade-up" data-fragment-index="1">
											<br>
											<div style="float:right; font-size: 20px;"  class="plain fragment fade-up" data-fragment-index="1"> Kipf & Welling  (2017)</div>
											<br >
										</section>

										<section>
												$$\forall i, \quad y_i = b + \underbrace{\color{orange}{\mathbf{W}_0} h_{i}}_{\tiny \mbox{self-connection}} + \underbrace{\sum\limits_{j \in \mathcal{N}_i} w_{i,j} \color{teal}{\mathbf{W}_1} h_j}_{\tiny \mbox{average over neighbors}}$$
											 <div class="container">
												 <div class="col">
														 <div class="fig-container fragment" data-fragment-index="1" data-file="graph_demo.html" data-style="height: 550px;"></div>
												 </div>
											 <div class="col">
													<img class="fragment" data-fragment-index="2" data-src="assets/3x3_kernel.png" style="width: 75%;"/><br>
													<span class="fragment" data-fragment-index="2">Equivalent 3x3 kernel</span>
											 </div>
										</div>
										</section>
										</section>

										 <section>
									  	 <section>
											 <h3 class="slide-title">Directional Graph Convolution</h3>

											 	Introduce additional kernels $\mathbf{W}_m$ and function $q_m(x_i, x_j)$ that decides which kernel an edge "sees", based on
												relative positions of both vertices.
												<br>
												<br>
											 		$$\forall i, \quad y_i = b + \color{orange}{\mathbf{W}_0} h_{i} + \sum\limits_{m = 1}^M \sum\limits_{j \in \mathcal{N}_i} q_{m}(\mathbf{x}_i, \mathbf{x}_j) \ w_{i,j} \ \mathbf{W}_m h_j$$
							<div style="float:right; font-size: 20px">adapted from Verma et al. (2017)</div>
													<br>
													<br>
													 <ul>
														 <li>$q_m(\mathbf{x}_i, \mathbf{x}_j) \propto \exp\left( \mathbf{u}_m^t (\mathbf{x}_i - \mathbf{x}_j)\right)$</li>
														 <br>
														 <li> $\sum_m q_m(\mathbf{x}_i,\mathbf{x}_j) = 1$</li>
													 </ul>
										 </section>

											<section>
												Let us consider an example with 4 directions $u_{m}$
												 <div class="container">
												 <div class="col">
														 <div class="fig-container" data-file="graph_demo2.html" data-style="height: 550px;"></div>
												 </div>

												<div class="col">
														Vector $u_{m}$ orientation: <br>
														<br>
														<div style="position:relative; width:200px; height:200px; margin:0 auto;">
														<svg xmlns="http://www.w3.org/2000/svg" class="fragment current-visible" style="position:absolute;top:0;left:0;" data-fragment-index="1" version="1.1" width="50%" height="50%" preserveAspectRatio="true" viewBox="2 4 28 24">
																<g class="shape-element" fill="rgb(255, 255, 255)">
																		<path d="M19.414 27.414l10-10c0.781-0.781 0.781-2.047 0-2.828l-10-10c-0.781-0.781-2.047-0.781-2.828 0s-0.781 2.047 0 2.828l6.586 6.586h-19.172c-1.105 0-2 0.895-2 2s0.895 2 2 2h19.172l-6.586 6.586c-0.39 0.39-0.586 0.902-0.586 1.414s0.195 1.024 0.586 1.414c0.781 0.781 2.047 0.781 2.828 0z"></path>
																</g>
														</svg>
														<svg xmlns="http://www.w3.org/2000/svg" class="fragment current-visible" style="position:absolute;top:0;left:0;" data-fragment-index="2" version="1.1" width="50%" height="50%" preserveAspectRatio="true" viewBox="4 2 24 28">
															<g class="shape-element" fill="rgb(255, 255, 255)">
															    <path d="M4.586 19.414l10 10c0.781 0.781 2.047 0.781 2.828 0l10-10c0.781-0.781 0.781-2.047 0-2.828s-2.047-0.781-2.828 0l-6.586 6.586v-19.172c0-1.105-0.895-2-2-2s-2 0.895-2 2v19.172l-6.586-6.586c-0.391-0.39-0.902-0.586-1.414-0.586s-1.024 0.195-1.414 0.586c-0.781 0.781-0.781 2.047 0 2.828z"></path>
															 </g>
														</svg>
														<svg xmlns="http://www.w3.org/2000/svg" class="fragment current-visible" style="position:absolute;top:0;left:0;" data-fragment-index="3" version="1.1" width="50%" height="50%" preserveAspectRatio="true" viewBox="2 4 28 24">
																<g class="shape-element" fill="rgb(255, 255, 255)">
																	<path d="M12.586 4.586l-10 10c-0.781 0.781-0.781 2.047 0 2.828l10 10c0.781 0.781 2.047 0.781 2.828 0s0.781-2.047 0-2.828l-6.586-6.586h19.172c1.105 0 2-0.895 2-2s-0.895-2-2-2h-19.172l6.586-6.586c0.39-0.391 0.586-0.902 0.586-1.414s-0.195-1.024-0.586-1.414c-0.781-0.781-2.047-0.781-2.828 0z"></path>
																</g>
														</svg>
														<svg xmlns="http://www.w3.org/2000/svg" class="fragment current-visible" style="position:absolute;top:0;left:0;" data-fragment-index="4" version="1.1" width="50%" height="50%" preserveAspectRatio="true" viewBox="4 2 24 28">
																<g class="shape-element" fill="rgb(255, 255, 255)">
																	<path d="M27.414 12.586l-10-10c-0.781-0.781-2.047-0.781-2.828 0l-10 10c-0.781 0.781-0.781 2.047 0 2.828s2.047 0.781 2.828 0l6.586-6.586v19.172c0 1.105 0.895 2 2 2s2-0.895 2-2v-19.172l6.586 6.586c0.39 0.39 0.902 0.586 1.414 0.586s1.024-0.195 1.414-0.586c0.781-0.781 0.781-2.047 0-2.828z"></path>
																</g>
														</svg>
							    			</div>
											</div>
										</div>
										$$\forall i, \quad y_i = b + \color{orange}{\mathbf{W}_0} h_{i} + \sum\limits_{m = 1}^M \sum\limits_{j \in \mathcal{N}_i} q_{m}(\mathbf{x}_i, \mathbf{x}_j) \ w_{i,j} \ \mathbf{W}_m h_j$$
									</section>
										 </section>

											<section>
												<h3 class="slide-title"> Wasserstein Generative Adversarial Networks</h3>
												<img data-src="assets/gen_models_diag_2.svg" style="background: #BBB;">
																<div style="float:right; font-size: 20px">Image credit: <a href="https://blog.openai.com/generative-models/">OpenAI</a></div>
												<ul>
													<li class="fragment">The WGAN (Arjovsky et al. 2017) is based on the Wasserstein distance between real $\mathbb{P}_r$ and generated $\mathbb{P}_\theta$ distributions:
														<br>
														<br>
															$$W(\mathbb{P}_r, \mathbb{P}_\theta) = \sup\limits_{||f_{\phi}||_L \leq 1} \mathbb{E}_{x \sim \mathbb{P}_r}[f_{\phi}(x)] - \underbrace{\mathbb{E}_{x \sim \mathbb{P}_\theta}[f_\phi(x)]}_{=\mathbb{E}_z[f_\phi(g_{\theta}(z))]}$$
													</li>
												</ul>
											</section>

											<section>
												<h3 class="slide-title">Graph Convolutional WGAN-GP</h3>
													<img class="plain" data-src="assets/gcn_gan.png">
													<br>
													<ul>
														<li>We use WGAN-Gradient Penalty (Gulrajani, 2017) to impose the Lipschitzness of $f_\phi$</li>
														<br>
														<li>Model can be made conditional by concatenating additional inputs to both generator and critic</li>
													</ul>

											</section>

											<section>

												<section>
													<h3 class="slide-title">Proof of concept on MNIST</h3>
													<div class="container">
																 <div class="col">
																	 <img class="plain" data-src="assets/mnist.png">
																	 <br>
																	 MNIST sample
																 </div>

																<div class="col">
																		<img class="plain" data-src="assets/mnist_example.png">
																		<br>
																		MNIST on random sensor graphs
																</div>
															</div>

												</section>

											<section>
												<h3 class="slide-title">Multiresolution approach</h3>
													<img data-src="assets/mnist_multi_resolution.png">
													<br>
													<ul>
															<li>Graph downsampling and upsampling operations based on Kron reduction and spectral sparsification (Shuman et al. 2013)
															</li>
							 						</ul>

													<img class="plain" data-src="assets/gspfrontpage.png" width="30%"><br>
													Checkout <a href="https://pygsp.readthedocs.io/">PyGSP</a>
											</section>

											<section>

													<div class="container">
																 <div class="col">
																	 <img class="plain" data-src="assets/mnist_example.png">
																	 <br>MNIST digits
																 </div>

																<div class="col">
																		<img class="plain" data-src="assets/graph_gan_example.png">
																		<br>Graph WGAN-GP samples
																</div>
															</div>
											</section>

											<section>
																 <div class="container">
																 <div class="col">
																	 <img class="plain" data-src="assets/mnist_graph.png">
																	<br> MNIST digits
																 </div>

																<div class="col">
																		<img class="plain" data-src="assets/wgangp_graph.png">
																		<br>Graph WGAN-GP samples
																</div>
															</div>
											</section>
										</section>

										<section>
											<section>
												<h3 class="slide-title">Application to Cosmological Simulations</h3>
													<img class='plain' data-src="assets/powerart.jpg">
													<div style="float:right; font-size: 20px">Khandai et al. (2014)</div>

													<ul>
														<li>Massive Black II hydrosimulation for training data</li>
													</ul>
											</section>

											<section>
													<ul>
														<li>We aim to predict <b>galaxy 3D major axis</b> given:</li>
															<ul>
																<li>Dark Matter masses </li>
																<li>Tidal field orientation, smoothed on 1 Mpc/h</li>
															</ul>
															<br>
															$\Longrightarrow$ Quantities readily available in large but low resolution simulations
															<br>
															<br>
															<li>Build k-nearest neighbors graphs within Dark Matter halos</li>
													</ul>
											</section>

											<section>
												<h3 class="slide-title">Alignment Correlation functions</h3>
													<img class="plain" data-src="assets/wgangp-ed.png"/>
													<img class="plain fragment fade-up" data-src="assets/wgangp-ee.png"/>

													<ul>
														<li class="plain fragment fade-up">Recovers alignments deep into non-linear regime</li>
													</ul>
											</section>

										</section>



										<section>
											<h3 class="slide-title"> takeaway message</h3>

											<br> <br>

											<div class="block ">
												<div class="block-title">
													Deep Learning for Emulating Complex Simulations
												</div>
												<div class="block-content">
													<ul>
														<li class="fragment"> New framework to empirically populate large volume
simulations with realistic galaxy populations.<br>
	$\Longrightarrow$  Will <b class="alert">add to the realism</b> of cosmological simulations. </li>
														<br>

														<li class="fragment">Neural networks on graphs are powerful tools for working with non
euclidean data.
											</li>

													</ul>
												</div>
											</div>
										</section>


							<section>
								<h1>Towards a New Inference Paradigm with Deep Learning </h1>
							</section>

							<section>
							<h3 class='slide-title'> traditional cosmological inference </h3>
							<div class='container'>
								<div class='col'>
									<div style="position:relative; width:480px; height:30px; margin:0 auto;">
									<div class="fragment current-visible" style="position:absolute;top:0;"  data-fragment-index="1">HSC cosmic shear power spectrum</div>
									<div class="fragment" style="position:absolute;top:0;"  data-fragment-index="2">HSC Y1 constraints on $(S_8, \Omega_m)$</div>
								</div>
									<div style="position:relative; width:480px; height:300px; margin:0 auto;">
										<div class="fragment current-visible"  style="position:absolute;top:0;left:0;" data-fragment-index="0" >
									  	<img class="plain" data-src="assets/alonso_g1.png" />
									  	<img class="plain" data-src="assets/alonso_g2.png" />
										</div>
									  <img class="fragment current-visible plain" data-src="assets/hsc_correlation_function.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
									  <img class="fragment  plain" data-src="assets/hsc_constraints.png" style="position:absolute;top:0;left:0;" data-fragment-index="2" />
									</div>
									<div class="fragment"  data-fragment-index="1" style="float:right; font-size: 20px">(Hikage, et al. 2018)</div>
								</div>

								<div class='col'>
							<ul>
								<li class="fragment" data-fragment-index="0"> Measure the ellipticity $\epsilon = \epsilon_i + \gamma$ of all galaxies<br>
		$\Longrightarrow$ Noisy tracer of the weak lensing shear $\gamma$ </li>
								<br>
								<li class="fragment" data-fragment-index="1"> Compute <b class="alert">summary statistics</b> based on 2pt functions, <br>e.g. the <b>power spectrum</b> </li>
								<br>
								<li class="fragment" data-fragment-index="2"> Run an  MCMC to recover a posterior on model parameters, using an <b class="alert">analytic likelihood</b>
										$$ p(\theta | x ) \propto \underbrace{p(x | \theta)}_{\mathrm{likelihood}}  \  \underbrace{p(\theta)}_{\mathrm{prior}}$$
								</li>
							</ul>
								</div>
							</div>

						<div class="block fragment">
							<div class="block-title">
								Main limitation: the need for an explicit likelihood
							</div>
							<div class="block-content">
							We can only compute the likelihood for <b>simple summary statistics</b> and on <b>large scales</b>
							<br>
							<br>
							<div class="fragment"> $\Longrightarrow$ We are dismissing most of the information! </div>
						</div>
					</div>
				</section>

				<section class="inverted" data-background="#000">
					<h2>
					Can I use a Deep Learning to perform proper Bayesian
							inference without likelihoods?</h2>
				</section>

				<section>
							<h3 class='slide-title'> let us rephrase the question </h3>

							<ul>
								<li class="fragment fade-up"> I assume a forward model of the observations:
							    \begin{equation}
							    		p( x ) = p(x | \theta) \ p(\theta) \nonumber
							    \end{equation}
							    All I ask is the ability to sample  from the model, to obtain $\mathcal{D} = \{x_i, \theta_i \}_{i\in \mathbb{N}}$
								</li>
								<br>
								<li class="fragment fade-up"> I am going to assume $q_\phi(\theta | x)$ a <b>parametric conditional density</b>
								</li>
								<br>
								<li class="fragment fade-up">Optimize the parameters $\phi$ of $q_{\phi}$ according to
											\begin{equation}
												\min\limits_{\phi}  \sum\limits_{i} - \log  q_{\phi}(\theta_i | x_i)   \nonumber
											\end{equation}
										In the limit of <b>large number of samples</b> and <b>sufficient flexibility</b>
										\begin{equation}
										\boxed{q_{\phi^\ast}(\theta | x) \approx p(\theta | x)}  \nonumber
										\end{equation}
								</li>
							</ul>

								<div style="position:relative; height:30px; margin-left: 4em;">
							<div class="fragment current-visible" style="position:absolute;top:0;"> $\Longrightarrow$ One can asymptotically recover the posterior by
								 optimizing  a <b>parametric estimator</b> over<br> the <b>Bayesian joint distribution</b>
							</div>
							<div class="fragment" style="position:absolute;top:0;"> $\Longrightarrow$ One can asymptotically recover the posterior by
								optimizing a <b class="alert">Deep Neural Network</b> over<br> a <b class="alert">simulated training set</b>.
							</div>
						</div>
				</section>

				<section>

							<h3 class='slide-title'> Neural Density Estimation </h3>

								<div class="container">
									<div class="col">
									  <img class="plain" data-src="assets/MDN.png" style="height:550px"/>
										<br>
									<div style="float:left; font-size: 20px">Bishop (1994)</div>
									</div>
									<div class="col">

										<ul>
										<li> Mixture Density Networks (MDN)
												\begin{equation}
												p(\theta | x)	 = \prod_i \pi_i(x) \  \mathcal{N}\left(\mu_i(x),  \ \sigma_i(x) \right) \nonumber
												\end{equation}
												 DELFI method (Alsing et al. 2018) based on Papamakarios & Murray (2016)
										</li>
										<br>

										<li class="fragment fade-up">Flourishing Machine Learning literature on density estimators
											<img class="plain" data-src="assets/glow.png" />
											<div style="float:right; font-size: 20px">GLOW, (Kingma & Dhariwal, 2018)</div>

										</li>

									</ul>
									</div>
								</div>
				</section>

				<section>
					<h3 class='slide-title'> deep residual networks for amortized inference </h3>

							<div class="container">

									<div class="col" style="flex: 0 0 15em;">
										<img class="plain" data-src="assets/deeplens.png"  style="height:550px"/><br>
										<div style="float:center; font-size: 20px">Lanusse & Lin, in prep.</div>
										</div>
										<div class="col" >
											<ul>
													<li> Deep Residual Network (ResNet-36) with mixture density output
													</li>
													<br>
													<li>Training on raw weak lensing maps simulated for different cosmologies</li>
							        <div class="container" >
													<div class="col" style="flex: 0 0 26em;">
													<img class="plain" data-src="assets/mass_maps.png"/><br>
												</div>
												<div class="col">
													<img class="plain" data-src="assets/TF_FullColor_Horizontal.png"/>
													<br>
													<br>
													<br>
													<img class="plain" data-src="assets/google-cloud-platform-logo.png"/>
												</div>
											</div>
	 											</ul>
									 </div>
							</div>
				</section>

				<section>

					<h3 class='slide-title'> extremely fast emulator for convergence maps</h3>

						<img class="plain" data-src="assets/LK_model_2.png" style="height: 300px;"/>

						<div class="container" >

								Lin & Kilbinger (2016)
												<div class="col">
													<img class="plain" data-src="assets/camelus.png" style="height: 300px;"/>

												</div>

												<div class="col">
													<img class="plain" data-src="assets/Maps_and_mask.png" style="height: 300px;"/>
												</div>
						</div>
				</section>

				<section>
					<h3 class='slide-title'> recovered posterior and validation</h3>
						25 sq. deg. with 8 gal/arcmin$^2$

						<div class="container" >

												<div class="col">
														<img class="plain" data-src="assets/sselfi-contours.png" style="height: 300px;"/>
<br>
<div class="fragment" data-fragment-index="1">
														Simulation-Based Calibration (Talts et al. 2018)

														\begin{equation}
   p(\theta) = \int p(\theta | \tilde{x} )  \  p(\tilde{x} | \tilde{\theta})  p(\tilde{\theta}) d \tilde{x} d \tilde{\theta} \nonumber
\end{equation}
$\longrightarrow$ Data averaged posterior reduces to prior
</div>
										</div>

												<div class="col">
													<div class="fragment" data-fragment-index="1">
														<img class="plain" data-src="assets/SBC-omega_m.png" />
														<img class="plain" data-src="assets/SBC-sigma8.png" />
													</div>
														<br>
												</div>
						</div>
				</section>


				<section>
					<h3 class="slide-title"> wait... what happened to summary statistics?</h3>

					<div class="container" class="fragment">
						<div class="col">
							<img class="plain" data-src="assets/nnexample.png"/>
						</div>

						<div class="col">
							<img class="plain" data-src="assets/mutual_information.png"/>
						</div>
					</div>

					<div class="block fragment">
						<div class="block-title">
							Dimensionality reduction by Variational Mutual Information Maximization
						</div>
						<div class="block-content">
							$$ I(y ; \theta) \ = \ \mathbb{E}_{y, \theta} [ \log p(\theta | y) ] + H(\Theta) \ \ge \ \mathbb{E}_{y, \theta} [ \log q_\phi(\theta | y) ] + H(\Theta) $$

							<ul>
								<li class="fragment">Not derived from Fisher information around a fiducial value, asymptotically optimal over
the entire parameter space</li>
								<br>
								<li class="fragment"> Comes for free by training a deep MDN with a bottleneck, can be reused</li>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<h3 class="slide-title"> takeaway message</h3>

					<br> <br>

					<div class="block ">
						<div class="block-title">
							Deep Learning For Cosmological Inference
						</div>
						<div class="block-content">
							<ul>
								<li class="fragment"> This is part of the broader class of Likelihood-Free Inference methods
<br>$\Longrightarrow$ Shifts the physics from signal modeling and statistics extraction to simulation </li>
								<br>

								<li class="fragment">Will be essential to maximize the scientific return of Stage IV surveys.
					</li>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<h1> Conclusion </h1>
				</section>


						<section>
							<h3 class="slide-title"> Conclusion </h3>

							<br> <br> <br>

													<div class="block ">
														<div class="block-title">
															Where can Deep Learning help for modern surveys?
														</div>
														<div class="block-content">
															<ul>
																<li class="fragment"> Open new and powerful ways to handle large volumes of complex data
																	<ul>
																		<li> Image detection for finding rare astrophysical objects</il>
																		<li> Deblending with deep data-driven priors</li>
																	</ul>
																</il>
																<br>

																<li class="fragment"> Data driven way of complementing our physical models
																	<ul>
																		<li> Fast emulation of galaxy properties in cosmological simulations</li>
																	</ul>
																</li>
																<br>
																<li class="fragment">  New strategies for inference for increasingly complex surveys

																</li>

															</ul>
													</div>
												</div>
													<br>
												<p class="fragment">Thank you ! </p>
																		 <br> <br>


						</section>

			</div>
		</div>


		<style>
		/* .reveal .slides {
		    border: 5px solid red;
		    min-height: 100%;
		    width: 128mm;
		    height: 96mm;
		} */

		.reveal .block {
			background-color: #191919;
			margin-left: 20px;
			margin-right: 20px;
			text-align: left;
			padding-bottom: 0.1em;
		}

		.reveal .block-title {
			background-color: #333333;
			padding:8px 35px 8px 14px;
  		color: #FFAA7F;
  		font-weight: bold;
		}

		.reveal .block-content {
			padding:8px 35px 8px 14px;
		}

		.reveal .slide-title {
			border-left: 5px solid white;
			text-align: left;
			margin-left: 20px;
			padding-left: 20px;
		}

		.reveal .alert {
  		color: #FFAA7F;
  		font-weight: bold;
		}

		.reveal .inverted {
			filter: invert(100%);
		}
/*
	    /* .reveal .alert {
	             padding:8px 35px 8px 14px; margin-bottom:18px;
	             text-shadow:0 1px 0 rgba(255,255,255,1);
	             border:5px solid #FFAA7F;
	             -webkit-border-radius: 14px; -moz-border-radius: 14px;
	             border-radius:14px
	             background-position: 10px 10px;
	             background-repeat: no-repeat;
	             background-size: 38px;
	             padding-left: 30px; /* 55px; if icon
	     }
	     .reveal .alert-block {padding-top:14px; padding-bottom:14px}
	     .reveal .alert-block > p, .alert-block > ul {margin-bottom:1em}
	     /*.reveal .alert li {margin-top: 1em}
	     .reveal .alert-block p+p {margin-top:5px} */

		</style>

		<script src="reveal.js/js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				controls: false,

				//center: false,
				hash: true,

				// Visibility rule for backwards navigation arrows; "faded", "hidden"
				// or "visible"
				controlsBackArrows: 'hidden',

				// Display a presentation progress bar
				progress: true,

				// Display the page number of the current slide
				slideNumber: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// The "normal" size of the presentation, aspect ratio will be preserved
				// when the presentation is scaled to fit different resolutions. Can be
				// specified using percentage units.
				width: 1280,
				height: 720,

				// Factor of the display size that should remain empty around the content
				margin: 0.1,

				// Bounds for smallest/largest possible scale to apply to content
				minScale: 0.2,
				maxScale: 1.5,

				dependencies: [
					{ src: 'reveal.js/plugin/markdown/marked.js' },
					{ src: 'reveal.js/plugin/markdown/markdown.js' },
					{ src: 'reveal.js/plugin/notes/notes.js', async: true },
					{ src: 'reveal.js/plugin/math/math.js', async: true },
					{ src: 'reveal.js/plugin/reveal.js-d3/reveald3.js' },
					{ src: 'reveal.js/plugin/reveal.js-plugins/chart/Chart.min.js' },
					{ src: 'reveal.js/plugin/reveal.js-plugins/chart/csv2chart.js' },
					{ src: 'reveal.js/plugin/highlight/highlight.js', async: true }
				]

			});
		</script>
	</body>
</html>
