<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Deep Generative Models for Galaxy Image Simulations</title>

		<meta name="description" content="Deep Generative Models of Galaxy Morphology">
		<meta name="author" content="Francois Lanusse">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<link rel="stylesheet" href="reveal.js/css/reset.css">
		<link rel="stylesheet" href="reveal.js/css/reveal.css">
		<link rel="stylesheet" href="reveal.js/css/theme/darkenergy.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="reveal.js/lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section data-background-image="assets/cosmos.jpg" >
						<div class="container">
							<div class="title" style="border-radius: 20px; background-color:rgba(0, 0, 0, 0.4);">
								<h1>Deep Generative Models for Galaxy Image Simulations</h1>
								<a href="ttps://arxiv.org/abs/2008.03833)"><img src="https://img.shields.io/badge/astro--ph.IM-arXiv%3A2008.03833-B31B1B.svg" class="plain" style="height:25px;"/></a> <a href="https://colab.research.google.com/github/McWilliamsCenter/galsim_hub/blob/master/notebooks/GalsimHubDemo.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" class="plain" style="height:25px;"/></a>

						</div>
					</div>

					<hr>
					<div style="border-radius: 20px; background-color:rgba(0, 0, 0, 0);">
						<h3>François Lanusse, Rachel Mandelbaum, Siamak Ravanbakhsh, Chun-Liang Li, Peter Freeman, Barnabas Poczos</h3>
												<div class="container" >
													<div class="col">
															<div align="left" style="margin-left: 20px;">
																<br>

															<img src="assets/CosmoStatDarkBK.png" class="plain"></img>
															<br>
															</div>
														</div>

														<div class="col">
															<img src="assets/logo_cnrs.png" class="plain" height="150"></img>
														</div>
														<div class="col">
															<img src="assets/desc-logo-inv.png" class="plain" height="200"></img>
														</div>
													</div>
													<div> slides at <a href="https://eiffl.github.io/talks/Lanusse2020">eiffl.github.io/talks/Lanusse2020</a> </div>
											</div>
					</section>
																	<section>
													          <section>
													            <h3 class="slide-title"> Impact of galaxy morphology on shape measurement</h3>
													       				<div class='container'>
													       					<div class='col'>
													                  <img class="plain" data-src="assets/real_gal-inv.png" style="height: 350px;"/>
													                  <br>
													                  <div style="float:left; font-size: 20px">Mandelbaum, et al. (2013), Mandelbaum, et al. (2014)</div>
													                </div>

													                <div class='col'>
													                  <img class="plain fragment fade-up" data-src="assets/great3_calib2-inv.png" style="height: 425px;"/>
													                </div>
													              </div>
													              <br>

													              <div class="block fragment fade-up">
													              <div class="block-title">
													               The need for data-driven generative models
													              </div>
													              <div class="block-content">
													                <ul>
													                  <li> Lack or inadequacy of physical model
													                  </li>
													                  <li> Extremely computationally expensive simulations
													                  </li>
													                </ul>
													            </div>
													            </div>
													          </section>
													      </section>

																<section class="inverted" data-background="#000">
																	<h2>
																	Can we learn a model for the signal from the data itself?</h2>
																</section>

													   			<section>
													   				<h3 class="slide-title"> The evolution of generative models </h3>

													   				<br> <br> <br>
													   				<div class='container'>
													   					<div class='col'>
													   						<div style="position:relative; width:500px; height:500px; margin:0 auto;">
													   							<img class="fragment current-visible plain" data-src="assets/DBN.png" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="0" />
													   							<img class="fragment current-visible plain" data-src="assets/vae_faces.jpg" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="1" />
													   							<img class="fragment current-visible plain" data-src="assets/gan-samples-1.png" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="2" />
													   							<img class="fragment plain" data-src="assets/karras2017.png" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="3" />
													   						</div>
													   					</div>

													   			<div class='col'>
													   				<ul>
													   					<li class="fragment" data-fragment-index="0"> Deep Belief Network <br> (Hinton et al. 2006) </li>
													   					<br>
													   					<li class="fragment" data-fragment-index="1"> Variational AutoEncoder <br> (Kingma & Welling 2014) </li>
													   					<br>
													   					<li class="fragment" data-fragment-index="2"> Generative Adversarial Network <br> (Goodfellow et al. 2014)</li>
													   					<br>
													   					<li class="fragment" data-fragment-index="3"> Wasserstein GAN <br> (Arjovsky et al. 2017) </li>
													   				</ul>
													   				</div>
													   			</div>
													   				<br> <br> <br>
													   			</section>

													        <!-- <section>
													  				<h3 class="slide-title"> A visual Turing test </h3>
													  				<div class="container">
													  						<div class="col">
													  							<img data-src="assets/samples_pixel_cnn.png" class="plain" style="height: 500px;" ></img>
													  							<br>
													  							<div class="fragment fade-up" data-fragment-index="0"> Fake PixelCNN samples </div>
													  						</div>
													  						<div class="col">
													  							<img data-src="assets/sdss5.png" class="plain"  style="height: 500px;" ></img>
													  							<br>
													  							<div class="fragment fade-up" data-fragment-index="0"> Real SDSS </div>
													  						</div>
													  				</div>
													  			</section> -->

													      <section>
													        <h3 class="slide-title"> Complications specific to astronomical images: spot the differences!</h3>

													        <div class="container">
													            <div class="col">
													              <img data-src="assets/celeba.png" class="plain" style="height: 450px;" ></img>
													              <br>
													              CelebA
													            </div>
													            <div class="col">
													              <img data-src="assets/hsc_images.png" class="plain"  style="height: 450px;" ></img>
													              <br>
													              HSC PDR-2 wide
													            </div>
													        </div>
													        <br>
													        <div >
													          <ul>
													            <li class="fragment"> There is <b class="alert">noise</b></li>
													            <li class="fragment"> We have a <b class="alert">Point Spread Function</b></li>
													          </ul>
													        </div>
													      </section>

																<section>
																     <section>
																        <h3 class="slide-title" style="position:absolute;top:0;">A Physicist's approach: let's build a model</h3>
																        <br>
																        <br>
																        <div class="container">
																          <div class="col">
																              <img class="plain fragment" data-src="assets/rand_z_square.png" style="height: 150px" data-fragment-index="4"/>
																          </div>
																          <div class="col">
																              <img class="plain fragment" data-src="assets/cosmos_gal.png" style="width: 200px" data-fragment-index="3"/>
																          </div>
																          <div class="col">
																            <img class="plain fragment" data-src="assets/cosmos_gal_psf.png" style="width: 200px" data-fragment-index="2"/>
																          </div>

																          <div class="col">
																            <img class="plain fragment" data-src="assets/cosmos_gal_pix.png" style="width: 200px" data-fragment-index="1"/>
																          </div>

																          <div class="col">
																            <img class="plain fragment" data-src="assets/cosmos_gal_ground.png" style="width: 200px" data-fragment-index="0"/>
																          </div>
																        </div>

																      <div class="container" style="position:relative; width:1000px; height:50px; margin:0 auto;">
																        <div class='col fragment' data-fragment-index='4'> <font size="10"> $\longrightarrow$ </font> <br> $g_\theta$ </div>
																        <div class='col fragment' data-fragment-index='3'> <font size="10"> $\longrightarrow$ </font> <br> PSF </div>
																        <div class='col fragment' data-fragment-index='2'> <font size="10"> $\longrightarrow$ </font> <br> Pixelation</div>
																        <div class='col fragment' data-fragment-index='1'> <font size="10"> $\longrightarrow$ </font> <br> Noise </div>
																      </div>

																      <div class="container">
																          <div class="col">
																            <div style="position:relative; width:400px; height:300px; margin:0 auto;">
																            <img data-src="assets/pgm_0.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:300px;" data-fragment-index="0"/>
																            <img data-src="assets/pgm_1.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:300px;" data-fragment-index="1"/>
																            <img data-src="assets/pgm_1.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:350px;" data-fragment-index="2"/>
																            <img data-src="assets/pgm_2.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:350px;" data-fragment-index="3"/>
																            <img data-src="assets/pgm_3.png" class="plain fragment " style="position:absolute;top:0;left:0;height:300px;" data-fragment-index="4"/>
																            </div>
																          </div>
																          <div class=" col">
																            <div class="block fragment" data-fragment-index="0">
																            <div class="block-title">
																             Probabilistic model
																            </div>
																            <div class="block-content">
																            <div style="position:relative; width:400px; height:100px; margin:0 auto;">
																              <div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="0"> $$ x \sim ? $$ </div>
																              <div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="1"> $$ x \sim \mathcal{N}(z, \Sigma) \quad z \sim ? $$<br>latent $z$ is a denoised galaxy image</div>
																              <div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="2"> $$ x \sim \mathcal{N}( \mathbf{P} z, \Sigma) \quad z \sim ?$$<br>latent $z$ is a super-resolved and denoised galaxy image</div>
																              <div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="3"> $$ x \sim \mathcal{N}( \mathbf{P} (\Pi \ast z), \Sigma) \quad z \sim ? $$<br>latent $z$ is a deconvolved, super-resolved, and denoised galaxy image </div>
																              <div class="plain fragment " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="4"> $$ x \sim \mathcal{N}( \mathbf{P} (\Pi \ast g_\theta(z)), \Sigma) \quad z \sim \mathcal{N}(0, \mathbf{I}) $$ <br>latent $z$ is a Gaussian sample<br> <b class="alert"> $\theta$ are parameters of the model</b> </div>
																            </div>
																            <br>
																            <br>
																            <br>
																          </div>
																          </div>
																          </div>
																      </div>
																      <div class="fragment"> $\Longrightarrow$ <b class="alert"> Decouples the morphology model from the observing conditions</b>.</div>
																     </section>

													      <section>
													        <h3 class="slide-title">How to train your <s>dragon</s> model</h3>
													        <div class="container">
													            <div class="col">
													              <img data-src="assets/pgm.png" class="plain" style="height: 300px;" ></img>
													            </div>
													            <div class="col">
													              <ul>
													                <li> Training the generative amounts to finding $\theta_\star$ that
													                  <b>maximizes the marginal likelihood</b> of the model:
													                    $$p_\theta(x | \Sigma, \Pi) = \int \mathcal{N}( \Pi \ast g_\theta(z), \Sigma) \ p(z) \ dz$$
													                    <div> $\Longrightarrow$ This is <b class="alert">generally intractable</b></div>
													                </li>
													                <br>
													                <li class="fragment fade-up"> Efficient training of parameter $\theta$ is made possible by <b class="alert">Amortized Variational Inference</b>.
													                </li>
													              </ul>
													            </div>
													        </div>

													        <div class="block fragment fade-up">
													        <div class="block-title">
													         Auto-Encoding Variational Bayes (Kingma & Welling, 2014)
													        </div>
													        <div class="block-content">
													          <ul>
													            <li class="fragment fade-up"> We introduce a <b>parametric distribution</b> $q_\phi(z | x, \Pi, \Sigma)$ which aims to model the
													            posterior $p_{\theta}(z | x, \Pi, \Sigma)$.
													            </li>
													            <br>
													            <li class="fragment fade-up"> Working out the KL divergence between these two distributions leads to:

													              $$\log p_\theta(x | \Sigma, \Pi) \quad \geq \quad - \mathbb{D}_{KL}\left( q_\phi(z | x, \Sigma, \Pi) \parallel p(z) \right) \quad + \quad \mathbb{E}_{z \sim q_{\phi}(. | x, \Sigma, \Pi)} \left[ \log p_\theta(x | z, \Sigma, \Pi)  \right]$$

													              $\Longrightarrow$ This is the <b>Evidence Lower-Bound</b>, which is differentiable with respect to $\theta$ and $\phi$.
													            </li>
													          </ul>
													      </div>
													      </div>

													      </section>
													      <section>
													      <h3 class="slide-title">The famous Variational Auto-Encoder</h3>
													      <img data-src="assets/vae.png" class="plain" style="height: 450px;"> </img>
													      <br>
													      <br>
													      $$\log p_\theta(x| \Sigma, \Pi ) \geq - \underbrace{\mathbb{D}_{KL}\left( q_\phi(z | x, \Sigma, \Pi) \parallel p(z) \right)}_{\mbox{code regularization}} + \underbrace{\mathbb{E}_{z \sim q_{\phi}(. | x, \Sigma, \Pi)} \left[ \log p_\theta(x | z, \Sigma, \Pi)  \right]}_{\mbox{reconstruction error}} $$
													      </section>

																<section>
														  				<h3 class="slide-title"> Sampling from the model</h3>
														            <div class="container">
														            <div class="col fragment fade-up">
														              <img data-src="assets/vae_samples_bad.png" class="plain" ></img>
														              Woups... what's going on?
														            </div>
														            <div class="col">
														              <img data-src="assets/latent_space.png" class="plain fragment fade-up" ></img>
														            </div>
														          </div>
														    </section>

																<section>
																	<h3 class="slide-title"> Tradeoff between code regularization and image quality</h3>

														      <br>
														      $$\log p_\theta(x| \Sigma, \Pi ) \geq - \underbrace{\mathbb{D}_{KL}\left( q_\phi(z | x, \Sigma, \Pi) \parallel p(z) \right)}_{\mbox{code regularization}} + \underbrace{\mathbb{E}_{z \sim q_{\phi}(. | x, \Sigma, \Pi)} \left[ \log p_\theta(x | z, \Sigma, \Pi)  \right]}_{\mbox{reconstruction error}} $$

														      <img data-src="assets/sdss_ae_kl.png" class="plain" ></img>

														    </section>

														    <section data-background-image=https://media.giphy.com/media/3o85xIO33l7RlmLR4I/source.gif>
														    </section>

																<section>
																	<h3 class="slide-title"> Latent space modeling with Normalizing Flows</h3>
														      <br>
														      $\Longrightarrow$ All we need to do is <b class="alert">sample from the aggregate posterior</b> of the data instead of sampling from the prior.

														    <br>
														    <br>

														    <div class="container">
														    <div class="col">
														      <img data-src="assets/flow_dinh_1.png" class="plain fragment fade-up" data-fragment-index="1"></img>
														      <img data-src="assets/flow_dinh_2.png" class="plain fragment fade-up" data-fragment-index="3"></img>

														      <br>
																 	<div class="fragment fade-up" style="float:right; font-size: 20px" data-fragment-index="1">Dinh et al. 2016</div>
														    </div>
														    <div class="col">
														              <div class="block fragment fade-up" data-fragment-index="1">
														              <div class="block-title">
														               Normalizing Flows
														              </div>
														              <div class="block-content">
														                <ul>
														                  <li> Assumes a <b class="alert">bijective</b> mapping between
														                    data space $x$ and latent space $z$ with prior $p(z)$:
														                    $$ z = f_{\theta} ( x ) \qquad \mbox{and} \qquad x = f^{-1}_{\theta}(z)$$
														                  </li>
														                  <li class="fragment" data-fragment-index="2"> Admits an explicit marginal likelihood:
														                    $$ \log p_\theta(x) = \log p(z) + \log \left| \frac{\partial f_\theta}{\partial x}  \right|(x)    $$
														                  </li>
														                </ul>
														            </div>
														            </div>
														            <br>
														              <br>
														              <br>
														              <br>
														    </div>
														</div>

														    </section>

																<section>
																	<h3 class="slide-title"> Conditional sampling in VAE latent space</h3>

																<div class="container">
																<div class="col">
																	<img data-src="assets/conditional_flow.png" class="plain" ></img>
																</div>
																	<div class="col">

																		<ul>
																			<li> We build a latent space model $p_\varphi(z)$ using a Masked Autoregressive Flow (MAF) (Papamakarios, et al. 2017)
																			</li>
																			<br>
																			<li class="fragment"> While we are learning to sample from the latent space, we can also <b class="alert"> learn to sample conditionaly</b>:
																						$$  p_\varphi(z | y) $$
																			</li>
																			<br>

																			<li class="fragment"> Here we learn to sample images conditioned on:
																				<ul>
																					<li> Size: half-light radius $r$
																					</li>
																					<li> Brightness: I band magnitude $mag\_auto$
																					</li>
																					<li> Redshift: COSMOS photometric redshift $zphot$
																					</li>
																				</ul>
																			</li>
																		</ul>
																	</div>
																</div>
															</section>
													      </section>

													      <section>
													  				<h3 class="slide-title"> Illustration on HST/ACS COSMOS images</h3>
													            <div class="container">
													            <div class="col">
													              <img data-src="assets/Figure_autoencode.png" class="plain" ></img>
													              <br>
													              <b>Fitting observations</b> with VAE and Bulge+Disk parametric model.
													            </div>
													            <div class="col">
													              <ul>
													                <li>Training set: <b>GalSim COSMOS HST/ACS postage stamps</b>
													                  <br>
													                  <ul>
													                    <li> 80,000 deblended galaxies from I < 25.2 sample
													                    </li>
													                    <li> Drawn on 128x128 stamps at 0.03 arcsec resolution
													                    </li>
													                    <li> Each stamp comes with:
													                      <ul>
													                        <li>PSF</li>
													                        <li>Noise power spectrum</li>
													                        <li>Bulge+Disk parametric fit</li>
													                      </ul>
													                    </li>
																							<br>

																							<li>Models are conditioned on:<br>
																								 mag_auto, flux_radius, zphot</li>
													                  </ul>
													                </li>
													                <br>
													                <li> Auto-Encoder model:
													                  <ul>
													                    <li> Deep residual autoencoder:<br> 7 stages of 2 resnet blocs each
													                    </li>
													                    <li> Dense bottleneck of size 16.
													                    </li>
													                    <li> Outputs positive, noiseless, deconvolved, galaxy surface brightness.
													                    </li>
													                  </ul>
													                </li>
													              </ul>
													            </div>
													        </div>
													      </section>

													  <section>

													  <section>
																<h3 class="slide-title"> Flow-VAE samples</h3>
													      <br>
													      <br>
													      <img class="current-visible plain" data-src="assets/lanusse2020_figure1.png"/>
													  </section>

														<section>
																<h3 class="slide-title">Second order moments</h3>

																<img class="current-visible plain" data-src="assets/lanusse2020_fig6a.png" style="width:550px;"/><br>
													      <img class="current-visible plain" data-src="assets/lanusse2020_fig6b.png" style="width:550px;"/>

														</section>

													  <section>
																<h3 class="slide-title"> Testing conditional sampling</h3>
													      <img data-src="assets/lanusse2020_figure7.png" class="plain"></img>
													    <div class="fragment">$\Longrightarrow$ We can successfully condition galaxy generation.</div>
													  </section>

													  <section>
																<h3 class="slide-title"> Testing galaxy morphologies </h3>

													      <br>
													      <br>

													    <img data-src="assets/gini_m20.png" class="plain"></img>

													<br>
													<br>
													  </section>
													</section>


											<section class="inverted" data-background="#000">
												<h2>
												How do we make these models useful in practice?</h2>
											</section>


													<section>
													<section>
																<h3 class="slide-title"> GalSim Hub: GalSim Interface and Online Repository of Morphology Models </h3>
																<br>
																<br>
															To make generative models easy to share and use, we introduce <b>GalSim Hub</b>:
															<ul>
																		<br><img data-src="assets/tfhub.png" class="plain" style="float:right;width:500px"></img><br>
																		<li >Defines a <b class="alert">specification for packaging</b> deep generative models as TensorFlow Modules. </li>
																		<br>
																		<br>
																		<li class="fragment">Provides a <b class="alert">GalSim interface</b> to seamlessly use deep generative models as any other lightprofiles.</li>
																		<br>
																		<br>
																		<li class="fragment" >Provides a community maintained <b class="alert">repository of trained models</b>.</li>
															</ul>
															<br>
															<br>
															<br>
															<div class="fragment">
															<img data-src="assets/github.png" class="plain" style="float:center;height:70px"/><br><a href="https://github.com/McWilliamsCenter/galsim_hub">https://github.com/McWilliamsCenter/galsim_hub</a>
														</div>
													</section>

													<section>
														<h3 class="slide-title">Minimum Working Example</h3>
														Assuming TensorFlow 1.15 and GalSim are already installed:
														<pre class="bash"><code data-trim data-noescape>
															$ pip install galsim-hub
															</code></pre>

													    <div class="container">
													    <div class="col fragment">
														<pre class="python"><code data-trim data-noescape>
import galsim
import galsim_hub
from astropy.table import Table

# Load generative model from the online repository
model = galsim_hub.GenerativeGalaxyModel(’hub:Lanusse2020’)

# Defines the input conditions
cat = Table([[5., 10. ,20.],
	     [24., 24., 24.],
	     [0.5, 0.5, 0.5]],
names=[’flux_radius’, ’mag_auto’, ’zphot’])

# Sample light profiles for these parameters
ims = model.sample(cat)

# Define a PSF
psf = galsim.Gaussian(sigma=0.06)

# Convolve by PSF
ims = [galsim.Convolve(im, psf) for im in ims]
															</code></pre>
															<div >
															<a href="https://colab.research.google.com/github/McWilliamsCenter/galsim_hub/blob/master/notebooks/GalsimHubDemo.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" class="plain" style="height:25px;"/></a>
															</div>
															</div>

													    <div class="col fragment">
							<pre class="yaml"><code data-trim data-noescape>
modules:
    - galsim_hub

psf:
    type: Gaussian
    sigma: 0.06  # arcsec

gal:
    type: GenerativeModelGalaxy
    flux_radius: { type: Random , min: 5, max: 10 }
    mag_auto: { type: Random , min: 24., max: 25. }
    zphot: { type: Random , min: 0.5, max: 1. }

image:
    type: Tiled
    nx_tiles: 10
    ny_tiles: 10
    stamp_size: 64  # pixels
    pixel_scale: 0.03  # arcsec / pixel
    noise:
       type: COSMOS

output:
    dir: output_yaml
    file_name: demo14.fits

input:
    generative_model:
        file_name: 'hub:Lanusse2020'
																	</code></pre>

															</div>
														</div>

													</section>

												<section>
													<h3 class="slide-title">Training and adding new models</h3>
													<br>

													<div class="block">
													<div class="block-title">
													 Galaxy2Galaxy: A framework for deep learning on astronomical data
													</div>
													<div class="block-content">
														<a href="https://github.com/ml4astro/galaxy2galaxy"><img data-src="https://img.shields.io/badge/github-ml4astro%2FGalaxy2Galaxy-blue" class="plain" style="height:25px;"/></a> <a href="https://gitter.im/ml4astro/galaxy2galaxy"> <img data-src="https://badges.gitter.im/ml4astro/galaxy2galaxy.svg" class="plain" style="height:25px;"/></a>
														<br>
														<ul>
															<li class="fragment">Building GalSim-based TensorFlow tf.data <b class="alert">Datasets</b><br>
																<pre class="bash"><code data-trim data-noescape>
$ g2g-datagen --problem=attrs2img_cosmos128 \
              --data_dir=datasets/attrs2img_cosmos128
																	</code></pre>
															</li>
															<li class="fragment">Train <b class="alert">various generative models</b>: VAE, GANs, PixelCNN
															<pre class="bash"><code data-trim data-noescape>
$ g2g-trainer --problem=attrs2img_cosmos128 \
              --data_dir=datasets/attrs2img_cosmos128 \
              --output_dir=models/vae \
              --model=continuous_autoencoder_residual_vae \
              --hparams_set=continuous_autoencoder_residual_128
																</code></pre></li>
															<li class="fragment"><b class="alert">Export models as GalSim-Hub</b> compatible modules

															<pre class="bash"><code data-trim data-noescape>
$ g2g-exporter --problem=attrs2img_cosmos128 \
               --data_dir=datasets/attrs2img_cosmos128 \
               --output_dir=models/vae \
               --model=continuous_autoencoder_residual_vae \
               --hparams_set=continuous_autoencoder_residual_128 \
               --export_dir=exported_models/vae
						 </code></pre><br>

						 $\Longrightarrow$ Once a model is exported, tgz it, and open a PR to host it on Galsim-Hub.

															</li>
														</ul>
												</div>
												</div>
												</section>

												</section>
													  <section>
																<h3 class="slide-title"> Takeaway message</h3>

													      <br>

													      <ul>
													        <li class="fragment"> We have <b class="alert">combined physical and deep learning components</b> to model
													          observed noisy and PSF-convoled galaxy images. <br>
													          $\Longrightarrow$ This framework can handle multi-band, multi-resolution, multi-instrument data.
													        </li>

													        <br>

													        <!-- <li class="fragment"> We are overcoming the limitations of standard VAEs with an additional latent space model.
													          <br>$\Longrightarrow$ Can produce sharp and meaningful images.
													        </li> -->

													        <br>

													        <li class="fragment"> We demonstrate conditional sampling of galaxy light profiles<br>
													          $\Longrightarrow$ Image simulation can be combined with larger survey simulation efforts, e.g. LSST DESC DC2
													        </li>

																	<br>
													      </ul>
													<br>
													<br>

													      <div class="block fragment fade-up">
													      <div class="block-title">
													        <b>GalSim Hub</b>
													      </div>
													      <div class="block-content">

													<br>

													      <div class="container">
													      <div class="col">
													        <img data-src="assets/TF_FullColor_Horizontal.png" class="plain"></img>
													      </div>

													      <div class="col">

													        <ul>

													          <li> Framework for sampling from deep generative models
													            directly from within GalSim.
													          </li>

													          <br>

													          <li>  Go check out the beta version: <a href="https://github.com/McWilliamsCenter/galsim_hub">https://github.com/McWilliamsCenter/galsim_hub</a>
													          </li>

													        </ul>

													      </div>
													      </div>

													    </div>
													    </div>

													  </section>

			</div>
		</div>

		<style>
		/* .reveal .slides {
				border: 5px solid red;
				min-height: 100%;
				width: 128mm;
				height: 96mm;
		} */

		.reveal .block {
			background-color: #191919;
			margin-left: 20px;
			margin-right: 20px;
			text-align: left;
			padding-bottom: 0.1em;
		}

		.reveal .block-title {
			background-color: #333333;
			padding:8px 35px 8px 14px;
			color: #FFAA7F;
			font-weight: bold;
		}

		.reveal .block-content {
			padding:8px 35px 8px 14px;
		}

		.reveal .slide-title {
			border-left: 5px solid white;
			text-align: left;
			margin-left: 20px;
			padding-left: 20px;
		}

		.reveal .alert {
			color: #FFAA7F;
			font-weight: bold;
		}

		.reveal .inverted {
			filter: invert(100%);
		}
		/*
			/* .reveal .alert {
							 padding:8px 35px 8px 14px; margin-bottom:18px;
							 text-shadow:0 1px 0 rgba(255,255,255,1);
							 border:5px solid #FFAA7F;
							 -webkit-border-radius: 14px; -moz-border-radius: 14px;
							 border-radius:14px
							 background-position: 10px 10px;
							 background-repeat: no-repeat;
							 background-size: 38px;
							 padding-left: 30px; /* 55px; if icon
			 }
			 .reveal .alert-block {padding-top:14px; padding-bottom:14px}
			 .reveal .alert-block > p, .alert-block > ul {margin-bottom:1em}
			 /*.reveal .alert li {margin-top: 1em}
			 .reveal .alert-block p+p {margin-top:5px} */

		</style>

		<script src="reveal.js/js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				controls: false,

				//center: false,
				hash: true,

				// Visibility rule for backwards navigation arrows; "faded", "hidden"
				// or "visible"
				controlsBackArrows: 'hidden',

				// Display a presentation progress bar
				progress: true,

				// Display the page number of the current slide
				slideNumber: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// The "normal" size of the presentation, aspect ratio will be preserved
				// when the presentation is scaled to fit different resolutions. Can be
				// specified using percentage units.
				width: 1280,
				height: 720,

				// Factor of the display size that should remain empty around the content
				margin: 0.1,

				// Bounds for smallest/largest possible scale to apply to content
				minScale: 0.2,
				maxScale: 1.5,

				dependencies: [
					{ src: 'reveal.js/plugin/markdown/marked.js' },
					{ src: 'reveal.js/plugin/markdown/markdown.js' },
					{ src: 'reveal.js/plugin/notes/notes.js', async: true },
					{ src: 'reveal.js/plugin/math/math.js', async: true },
					{ src: 'reveal.js/plugin/reveal.js-d3/reveald3.js' },
					{ src: 'reveal.js/plugin/reveal.js-plugins/chart/Chart.min.js' },
					{ src: 'reveal.js/plugin/reveal.js-plugins/chart/csv2chart.js' },
					{ src: 'reveal.js/plugin/highlight/highlight.js', async: true },
				]

			});

		</script>
	</body>
</html>
