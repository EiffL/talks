<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Deep Learning for Astronomical Image Processing</title>

	<meta name="description" content="November 18th 2020">
	<link rel="stylesheet" href="reveal.js/dist/reset.css">
	<link rel="stylesheet" href="reveal.js/dist/reveal.css">
	<link rel="stylesheet" href="reveal.js/dist/theme/darkenergy.css" id="theme">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css" id="highlight-theme">
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section data-background-image="assets/lsst_stills_0009_crop.jpg">
				<div class="container">
					<div class="title" style="border-radius: 20px; background-color:rgba(0, 0, 0, 0.4);">
						<h1>Deep Learning for Astronomical Image Processing</h1>
						<h2>InTheArt Seminar, Nov. 20th 2020</h2>
					</div>
				</div>
				<hr>
				<div style="border-radius: 20px; background-color:rgba(0, 0, 0, 0);">
					<div class="container">
						<div class="col">
							<div align="left" style="margin-left: 20px;">
								<h2>François Lanusse</h2>
								<br>
								<img src="assets/CosmoStatDarkBK.png" class="plain"></img>
								<br>
							</div>
						</div>

						<div class="col">
							<br>
							<br>
							<br>
							<br>
							<img src="assets/logo_cnrs.png" class="plain" height="150"></img>
						</div>

						<div class="col">
							<br>

							<br>
							<br>
							<img src="assets/aim.png" class="plain" height="150"></img>
						</div>
					</div>
					<div> slides at <a href="https://eiffl.github.io/talks/ITA2020">eiffl.github.io/talks/ITA2020</a> </div>
				</div>
			</section>


			<!-- <section data-background-image="assets/WMAP_timeline_large.jpg">
			<h3 class='slide-title' style="position:absolute;top:0;"> the $\Lambda$CDM view of the Universe </h3>
			<br>	<br>
			<div class="container">
			<div class="col" style="flex: 0 0 40em;">

		</div>
		<div class="col">

		<img class="plain" data-src="assets/Euclid.png" style="width: 300px"/>

		<img class="plain" data-src="assets/wfirstlogo.png" style="width: 300px"/>

		<img class="plain" data-src="assets/vrro.png" style="width: 300px"/>
	</div>
</div>
<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>
</section> -->

<section>
	<section data-background-video="assets/animation-day-to-night.mov" data-background-video-muted>
		<h3 class='slide-title'>the Rubin Observatory Legacy Survey of Space and Time</h3>
		<div class="container">
			<div class="col">
				<ul>
					<li class="fragment fade-up"> 1000 images each night, 15 TB/night for 10 years</li>
					<br>
					<li class="fragment fade-up"> 18,000 square degrees, observed once every few days</li>
					<br>
					<li class="fragment fade-up"> Tens of billions of objects, each one observed $\sim1000$ times</li>
				</ul>
				<br >
				<!-- <p class="fragment fade-up"> $\Longrightarrow$ Incredible potential for discovery, along with <b>unprecedented challenges</b >.</p> -->
			</div>

			<div class="col">
				<video class="fragment fade-up"  data-fragment-index="1" data-autoplay data-src="assets/obsim.mp4" type="video/mp4" />
			</div>
		</div>
	</section>


	<section data-transition="fade-in fade-out" data-background="assets/gal_sdss.png" data-vertical-align-top>
		<p>Previous generation survey: SDSS</p>
		<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>
		<br>	<br>	<br>	<br>	<br>	<br>	<br>
		<div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
	</section>
	<section data-transition="fade-in fade-out" data-background="assets/gal_des.png" data-vertical-align-top>
		<p>Current generation survey: DES</p>
		<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>
		<br>	<br>	<br>	<br>	<br>	<br>	<br>
		<div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
	</section>
	<section data-transition="fade-in fade-out" data-background="assets/gal_hsc.png" data-vertical-align-top>
		<p>LSST precursor survey: HSC</p>

		<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>
		<br>	<br>	<br>	<br>	<br>	<br>	<br>
		<div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
	</section>
</section>



							<section>
								<h3  class='slide-title'>Outline of this talk</h3>
								<br>
								<br>
								<h3> Where can Deep Learning help address the challenges of modern surveys ?</h4>
								<br>
								<br>
								<ul>
									<li class="fragment grow">Low level image processing</li>
									<br>
									<br>
									<li  class="fragment grow">Solving Inverse Problems</li>
									<br>
									<br>
									<li  class="fragment grow">Probabilistic inference</li>
								</ul>
								<br>
								<br>
								<br>
								<br>
							</section>

							<section>
								<h2>Deep detection of gravitational lenses</h2>
								<a href="https://arxiv.org/abs/1703.02642"><img src="https://img.shields.io/badge/astro--ph.IM-arXiv%3A1703.02642-B31B1B.svg" class="plain" style="height:25px;" /></a>
								<hr>
								<div class="container">
									<div class="col">
										<div align="left" style="margin-left: 20px;">
											<h3>Work in collaboration with: <br>
											</h3>
											<h4>
												Quanbin Ma, Nan Li, Thomas E. Collett, Chun-Liang Li, Siamak Ravanbakhsh, Rachel Mandelbaum, Barnabas Poczos
											</h4>

											<br> <br> <br>

											$\Longrightarrow$ Use Deep Neural Networks to detect rare objects
										</div>
									</div>
									<div class="col">
										<img src="assets/huang2019.png" style="width:450px;" />
									<div style="float:right; font-size: 20px">Huang et al. (2019) - arXiv:1906.00970</div>
									</div>
								</div>
								<br>
							</section>

							<section data-background-image="assets/eso1313b.jpg">
								<h3 class='slide-title'> Galaxy-Galaxy Strong Lensing</h3>
								<br>
								<br>
										<img data-src="assets/lente_todas.jpg" class="fragment fade-up" style="height: 550px;"/>
<br>
<br>
<br>
							</section>


							<section>
								<h3 class='slide-title'>example of application: gravitational time delays</h3>

								<div class="container">
									<div class="col">
										<img data-src="assets/figure3.jpg" class="plain" style="height: 400px;">
									</div>
									<div class="col">
										<img data-src="assets/heic1702b.jpg" class="plain" style="height: 400px;">
									</div>
								</div>
								<div >
										<script type="math/tex; mode=display">
									 		\Delta t_{i j} = \frac{1 + z_{L}}{c} \ \underbrace{\frac{D_{L} \  D_{S}}{ D_{L S}}}_{\propto \ H_0^{-1}} \ \left[ \frac{(\theta_i -\beta)^2}{2} - \psi(\theta_i) + \frac{(\theta_j - \beta)^2}{2} + \psi(\theta_j) \right]
									</script>
								</div>
						</section>

						<section data-background="assets/fig1w.png">
						</section>

						<section data-background="assets/fig1.png">
						</section>

						<section data-background="assets/hsc_illustration_tract.png">
							<h3>WWAD: <span class="fragment">What Would an Astrophysicist Do ?</span></h3>
							<div class="fragment fade-up">
							<img data-src="assets/fig2.png" style="height: 525px;">
							<div class="container">
								<div class="col"> gri composite </div>
								<div class="col"> g - $\alpha$ i </div>
								<div class="col"> detected areas </div>
								<div class="col"> HST images </div>
							</div>
							<div style="float:right; font-size: 20px;"> RingFinder (Gavazzi et al. 2014) </div>
							</div>
						 	<br>
					  	</section>

							<section>
								<canvas data-chart="bar">
								<!--
								{
								 "data": {
								  "labels": ["CFHTLS"," DES", "LSST"],
								  "datasets": [
								   {
								    "data":[220, 2400, 120000],
								    "label":"Number of strong lenses","backgroundColor":"#374A67"
								   },
								   {
								    "data":[75, 2500, 10000],
								    "label":"Person-hour required for visual inspection [RingFinder]","backgroundColor":"#A63446"
								   }
								  ]
								 },
								 "options": { "responsive": "true",
			        "scales": {
			            "yAxes": [{
			                "type": "logarithmic"
			            }]
			        }
			 					}
								}
								-->
							</canvas>
							<div style="float:right; font-size: 20px">Gavazzi et al. (2014), Collett (2015)</div>
								<br>
								<div class="fragment fade-up">$\Longrightarrow$ Plainly intractable at the scale of LSST</div>
							</section>

							<section>
								<h3> A conventional Convolutional Neural Network</h3>
								<img data-src="assets/single_layer.png" class="plain"></img>
							</section>

							<section>
								<div class="container">
									<div class="col">
										<img height="600px" data-src="assets/residual_unit.png" class="plain">
										<br>
										Preactivated Residual Unit<br> (He et al. 2016)
									</div>
									<div class="col fragment">
										<img height="600px"  data-src="assets/deeplens.png" class="plain">
										<br>
										CMUDeepLens Architecture<br> (Lanusse et al. 2017)
									</div>
							</section>

							<section>
								<h3>Some CMUDeepLens results</h3>
								<div class="container">
									<div class="col">
								<img height=200 data-src="assets/candidates.png" class="plain">
								<br>
								<br>
								True Positive Rate = $\frac{TP}{TP + FN}$
								<br>
								<br>
								<ul>
									<li> $TP$: True Positives
									<li> $FN$: False Negatives
								</ul>
							</div>
									<div class="col">
										<img height=200 data-src="assets/roc_curves.png" class="plain">
									<br>
									<br>
									False Positive Rate = $\frac{FP}{FP + TN}$
									<br>
									<br>
									<ul>
										<li> $FP$: False Positives
										<li> $TN$: True Negatives
									</ul>
								</div>
							</div>
							</section>

							<section>
								<h3 class="slide-title">The Euclid strong-lens finding challenge</h3>
								<div style="float:right; font-size: 20px">Metcalf, . . ., Lanusse, et al. (2018)</div>
								<br>
								<div class="container">
									<div class="col">
										<img height=500 data-src="assets/ground_lenses.png"></img>
									</div>
									<div class="col">
										<img height=500 data-src="assets/space_based.jpg"></img>
									</div>
								</div>
								<section>
								<img data-src="assets/roc_ground_small.png" class="plain fragment fade-up" style="height: 500px;"></img>

								<br> <br>

								<div class="fragment fade-up"> Better accuracy than human visual inspection !</div>
							</section>
							</section>

							<section>
									<h3 class="slide-title"> CMU DeepLens in the wild</h3>
									<img height=550 data-src="assets/huang2019.png"></img>
									<div style="float:center; font-size: 20px">Huang et al. (2019) - arXiv:1906.00970</div>

							</section>

							<section>
								<h3 class="slide-title"> takeaway message</h3>

								<br> <br>

								<div class="block ">
									<div class="block-title">
										Deep Learning for Low Level Processing
									</div>
									<div class="block-content">
										<ul>
											<li class="fragment"> An example of Deep Learning allowing us to handle
												the <b class="alert">volume and data rate</b> at the image level</li>
											<br>

											<li class="fragment"> Our automated lens finder is faster and more reliable than human volunteers.
												<br> $\Longrightarrow$  Larger and more robust samples for the science analysis.
											</li>
											<br>

										</ul>
									</div>
								</div>
							</section>

								<section>
									<h2>Hybrid physics-ML models for image inverse problems </h2>

									<a href="https://arxiv.org/abs/1912.03980"><img src="https://img.shields.io/badge/astro--ph.IM-arXiv%3A1912.03980-B31B1B.svg" class="plain" style="height:25px;" /></a>
									<a href="https://www.youtube.com/watch?v=oWOU3qNHoL0"><img src="https://img.shields.io/badge/-youtube-red?logo=youtube&labelColor=grey" class="plain" style="height:25px;" /></a>
									<hr>
									<div class="container">
										<div class="col">
											<div align="left" style="margin-left: 20px;">
												<h3>Work in collaboration with: <br>
													Peter Melchior, Fred Moolekamp
												</h3>

												<br> <br> <br>

												$\Longrightarrow$ Use PixelCNNs as deep priors for deblending
											</div>
										</div>
										<div class="col">
											<img src="assets/scarlet_data.png" style="width:450px;" />
										</div>
									</div>
									<br>
								</section>

														<section>
														<section data-background="assets/gal_hsc.png">

														</section>
														 				<section>
														 					<h3 class="slide-title">The challenge of galaxy blending</h3>
																					<div class="container">
																							<div class="col">
																								<div style="position:relative; width:480px; height:500px; margin:0 auto;">
																									<img class="fragment current-visible plain"  data-src="assets/hsc_deblending_success.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
																									<img class="fragment plain" data-src="assets/hsc_shredded.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
																								</div>
																								<div class="fragment" data-fragment-index="0" style="float:left; font-size: 20px">Bosch et al. 2017</div>
																							</div>
																							<div class="col">
																							<ul>
																								<li class="fragment fade-up" data-fragment-index="0"> In HSC over 60% of all galaxies are blended</li>
																								<br>
																								<li class="fragment fade-up" data-fragment-index="0"> Important impact on our main cosmological probes</li>
																								<br>
																								<li class="fragment fade-up" data-fragment-index="1"> Current generation of deblenders does not meet our target requirements</li>
																								<br>
																								<ul class="fragment fade-up" data-fragment-index="2">
																									<li> Existing methods rely on simple assumptions about galaxy profiles, like <i>symmetry</i> or <i>monotonicity</i></li>
																								</ul>
																							</ul>
																							</div>
																					</div>

																					<div class="fragment fade-up"data-fragment-index="3" >
																						Deblending is an ill-posed inverse problem, akin to <i>Blind Source Separation</i>. The is no <b>single solution</b>.<br>
																						$\Longrightarrow$ Intuitively, the key will to leverage an understanding of how individual <i>galaxies look like</i>.
																					</div>
														 				</section>
																		</section>


																		<section>
																						<section data-background="assets/gal_hsc.png">
																							<h3 class='slide-title'>Can AI solve all of our problems?</h3>
																							<div class="fragment">
																								<div style="float:right; font-size: 20px">Branched GAN model for deblending <a href="https://arxiv.org/abs/1810.10098">(Reiman & Göhre, 2018)</a></div>

																								<img class="plain" data-src="assets/Reiman2018_1.png" />
																							</div>

																							<div class="block fragment">
																								<div class="block-title">
																									The issue with using deep learning as a <i>black-box</i>
																								</div>
																								<div class="block-content">
																									<ul>
																										<li> No explicit control of noise, PSF, depth, number of sources.
																											<ul>
																												<li> Model would have to be retrained for all observing configurations
																												</li>
																											</ul>
																										</li>
																										<li class="fragment"> No guarantees on the network output (e.g. flux preservation, artifacts)
																										</li>
																										<li class="fragment"> No proper uncertainty quantification.
																										</li>
																									</ul>
																								</div>
																							</div>
																						</section>

																						<section>
																							<img class="plain" data-src="assets/Reiman2018_3.png" />
																						</section>
																					</section>


																		<section>
																		<section>
																			<h3 class="slide-title">Linear inverse problems</h3>

																			$\boxed{y =  \mathbf{A}x + n}$
																			<br>
																			<br>
																			$\mathbf{A}$ is known and encodes our physical understanding of the problem.
																			<span class="fragment"><br>$\Longrightarrow$ When non-invertible or ill-conditioned, the inverse problem is ill-posed with no unique solution $x$</span>
																			<div class="container fragment fade-up">
																					<div class="col">
																						<img data-src="assets/pluto_smooth.png" class="plain"></img>
																						Deconvolution
																					</div>
																					<div class="col">
																						<img data-src="assets/pluto_missing.png" class="plain"></img>
																						Inpainting
																					</div>
																					<div class="col">
																						<img data-src="assets/plutoNoise.png" class="plain"></img>
																						Denoising
																					</div>
																			</div>

																		</section>

																		<section data-vertical-align-top>
																			$\boxed{y =  \mathbf{A}x + n}$
																			<br>
																			<br>
																			The Bayesian view of the problem:
																			<br>
																			<br>
																			$$ p(x | y) \propto p(y | x) \ p(x) $$
																			<br>

																			<ul>
																				<li class="fragment fade-up">$p(y | x)$ is the data likelihood, which <b>contains the physics</b><br>
																				</li>
																				<br>
																				<li class="fragment fade-up">$p(x)$ is our prior knowledge on the solution.</li>
																			</ul>
																			<br>
																			<br>
																			<div class="fragment fade-up">
																			With these concepts in hand, we want to estimate the Maximum A Posteriori solution:
																			<br>
																			<br>
																			$$\hat{x} = \arg\max\limits_x \ \log p(y \ | \ x)  + \log p(x)$$
																			<br>
																			For instance, if $n$ is Gaussian, $\hat{x} = \arg\max\limits_x \ \frac{1}{2} \parallel y - \mathbf{A} x \parallel_{\mathbf{\Sigma}}^2 + \log p(x)$
																			</div>
																			<br>
																			<div class="fragment fade-up">
																				<h3>How do you choose the prior ?</h3>
																			</div>
																		</section>

																		<section>
																			<h3 class="slide-title"> Classical examples of signal priors </h3>
																				<div class="container">
																					<div class="col">
																						Sparse
																						<img data-src="assets/wavelet.png" height="400" class="plain"></img><br>
																						$$ \log p(x) = \parallel \mathbf{W} x \parallel_1 $$
																					</div>
																					<div class="col">
																						Gaussian
																						<img data-src="assets/zknj8.jpg" height="400" class="plain"></img>
																						$$ \log p(x) = x^t \mathbf{\Sigma^{-1}} x $$
																					</div>
																					<div class="col">
																						Total Variation
																						<img data-src="assets/shepp-Logan.ppm" class="plain"></img>
																						$$ \log p(x) = \parallel \nabla x \parallel_1 $$

																					</div>
																			</div>
																		</section>

																		<section data-background="assets/hsc_screen.png">
																				<h2>But what about this?</h2>

																		</section>
																	</section>

																	<section class="inverted" data-background="#000">
																		<h2>
																		Can we use Deep Learning to learn the prior from data?</h2>
																	</section>


																	<section>
																		<h3 class="slide-title"> The evolution of generative models </h3>

																		<br> <br> <br>
																		<div class='container'>
																			<div class='col'>
																				<div style="position:relative; width:480px; height:300px; margin:0 auto;">
																					<img class="fragment current-visible plain" data-src="assets/DBN.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
																					<img class="fragment current-visible plain" data-src="assets/vae_faces.jpg" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
																					<img class="fragment current-visible plain" data-src="assets/gan-samples-1.png" style="position:absolute;top:0;left:0;" data-fragment-index="2" />
																					<img class="fragment plain" data-src="assets/karras2017.png" style="position:absolute;top:0;left:0;" data-fragment-index="3" />
																				</div>
																			</div>

																	<div class='col'>
																		<ul>
																			<li class="fragment" data-fragment-index="0"> Deep Belief Network <br> (Hinton et al. 2006) </li>
																			<br>
																			<li class="fragment" data-fragment-index="1"> Variational AutoEncoder <br> (Kingma & Welling 2014) </li>
																			<br>
																			<li class="fragment" data-fragment-index="2"> Generative Adversarial Network <br> (Goodfellow et al. 2014)</li>
																			<br>
																			<li class="fragment" data-fragment-index="3"> Wasserstein GAN <br> (Arjovsky et al. 2017) </li>
																		</ul>
																		</div>
																	</div>
																		<br> <br> <br>
																	</section>

																	<section>
																		<h3 class="slide-title"> A visual Turing test </h3>
																		<div class="container">
																				<div class="col">
																					<img data-src="assets/samples_pixel_cnn.png" class="plain" style="height: 500px;" ></img>
																					<br>
																					<div class="fragment fade-up" data-fragment-index="0"> Fake PixelCNN samples </div>
																				</div>
																				<div class="col">
																					<img data-src="assets/sdss5.png" class="plain"  style="height: 500px;" ></img>
																					<br>
																					<div class="fragment fade-up" data-fragment-index="0"> Real SDSS </div>
																				</div>
																		</div>
																	</section>


																				<section data-vertical-align-top>
																					<h3 class="slide-title">Not all generative models are created equal</h3>
																					<img data-src="assets/generative_models_table.png" class="plain"></img>
																					<div style="float:right; font-size: 20px">Grathwohl et al. 2018</div>
																					<br>
																					<br>
																					<ul>
																						<li> GANs and VAEs are very common and successfull but do not fit our purposes.</li>
																						<br>
																						<li> We want a model which can <b class="alert">provide an explicit $\log p(x)$.</b></li>
																						<br>
																					</ul>
																				</section>

																				<section>
																					<h3 class="slide-title">PixelCNN: Likelihood-based Autoregressive generative model</h3>

																					<div class="container">
																						<div class="col">
																							Models the probability $p(x)$ of an image $x$ as:
																							$$ p_{\theta}(x) = \prod_{i=0}^{n} p_{\theta}(x_i | x_{i-1} \ldots x_0) $$
																							<ul>
																								<li>Some of the best log-likelihoods on the market.</li>
																								<li>Extremely stable during training.</li>
																								<li>Slow to sample from.</li>
																							</ul>
																							<br>
																							<br>

																							<div class="fragment fade-up">
																								<img data-src="assets/speedup.gif" class="plain"></img>
																								<br>
																								<div style="float:left; font-size: 20px">Ramachandran et al. 2017</div>
																							</div>
																						</div>

																						<div class="col">
																							<img data-src="assets/pixel_cnn_conv.png" class="plain"></img>
																							<div style="float:right; font-size: 20px">van den Oord et al. 2016</div>
																						</div>
																					</div>
																					<br>
																					<ul>
																						<li class="fragment"> Provides an explicit value for $\log p_\theta(x)$<br>
																							$\Longrightarrow$ <b class="alert">Can be used as a Bayesian prior for inverse problems.</b>
																						</li>
																					</ul>
																				</section>

																				<section>
																					<h3 class="slide-title">A deep denoising example</h3>
																					$$ \boxed{{\color{Orchid} y}  = {\color{SkyBlue} x} + n} $$
																					<div class="container">
																						<div class="col">
																							<div class="fig-container" data-file="dgm_prior_denoising.html" data-style="height: 550px;"></div>
																							Try me out at: <a href="https://eiffl.github.io/DeepPriors">https://eiffl.github.io/DeepPriors</a>
																						</div>

																						<div class="col">
																							<ul>
																								<li>We learn the <b class="alert">distribution of noiseless data $\log p_\theta(x)$</b> from samples using a deep generative model.</li>
																								<br>
																								<li class="fragment"> We measure a noisy ${\color{Orchid} y}$ and we want to estimate a denoised ${\color{SkyBlue} x}$</li>
																								<br>
																								<li class="fragment">The solution should lie on the <b class="alert">realistic data manifold</b>, symbolized by the two-moons distribution.

																									<p> We want to solve for the Maximum A Posterior solution: </p>
																									$$\arg \max - \frac{1}{2} \parallel {\color{Orchid} y} - {\color{SkyBlue} x} \parallel_2^2 + \log p_\theta({\color{SkyBlue} x})$$

																									This can be done by <b class="alert">gradient descent</b> as long as one has access to $\frac{\color{orange} d \color{orange}\log \color{orange}p\color{orange}(\color{orange}x\color{orange})}{\color{orange} d \color{orange}x}$.
																								</li>
																							</ul>
																					</div>
																		</div>
																		</section>

																		<section>
																			<h3 class="slide-title"> The Scarlet algorithm: deblending as an optimization problem</h3>
																			<div style="float:right; font-size: 20px">Melchior et al. 2018</div>

																			$$ \mathcal{L} = \frac{1}{2} \parallel \mathbf{\Sigma}^{-1/2} (\ Y - P \ast A S \ ) \parallel_2^2 - \sum_{i=1}^K \log p_{\theta}(S_i) + \sum_{i=1}^K g_i(A_i) + \sum_{i=1}^K f_i(S_i)$$

																			<div class="container">
																				<div class="col">
																					<img data-src="assets/scarlet_data.png" height=450 class="plain"></img>
																				</div>

																				<div class="col">

																					Where for a $K$ component blend:
																					<br>
																					<ul>
																						<li>$P$ is the convolution with the instrumental response</li>
																						<br>
																						<li>$A_i$ are channel-wise galaxy SEDs, $S_i$ are the morphology models</li>
																						<br>
																						<li>$\mathbf{\Sigma}$ is the noise covariance</li>
																						<br>
																						<li><b class="alert">$\log p_\theta$ is a PixelCNN prior</b></li>
																						<br>
																						<li>$f_i$ and $g_i$ are arbitrary additional non-smooth consraints, e.g. positivity, monotonicity...</li>
																					</ul>
																				</div>
																			</div>

																			<span class="fragment fade-up">$\Longrightarrow$ Explicit physical modeling of the observed sky</span>
																		</section>

																		<section>
																			<h3 class="slide-title">Training the morphology prior</h3>

																			<div class="container">
																				<div class="col">
																					<img data-src="assets/cosmos_training.png" height=450 class="plain"></img>
																					<div> Postage stamps of isolated COSMOS galaxies used for training, at WFIRST resolution and fixed fiducial PSF</div>
																				</div>

																				<div class="col">
																					<div class="container fragment fade-in">
																						<div class="col">
																							isolated galaxy
																							<img data-src="assets/gal_1.png" class="plain"></img>
																							<span> $\log p_\theta(x) = 3293.7$ </span>
																						</div>

																						<div class="col">
																							artificial blend
																							<img data-src="assets/gal_2.png" class="plain"></img>
																							<span> $\log p_\theta(x) = 3100.5 $ </span>
																						</div>
																					</div>
																				</div>
																		</section>

																		<section>
																			<section>
																				<h3 class="slide-title">Scarlet in action</h3>

																				<div class="container">
																					<div class="col">
																						Input blend
																						<div style="position:relative; width:480px; height:480px; margin:0 auto;">
																							<img data-src="assets/scar_input.png" class="plain"></img>
																						</div>
																					</div>

																					<div class="col">
																						<span class="fragment" data-fragment-index="0">Solution</span>
																						<div style="position:relative; width:480px; height:480px; margin:0 auto;">
																							<img class="fragment current-visible plain" data-src="assets/old_rec.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
																							<img class="fragment  plain" data-src="assets/pix_rec.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
																						</div>
																					</div>

																					<div class="col">
																						<span class="fragment" data-fragment-index="0">Residuals</span>
																						<div style="position:relative; width:480px; height:480px; margin:0 auto;">
																							<img class="fragment current-visible plain" data-src="assets/old_res.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
																							<img class="fragment  plain" data-src="assets/pix_res.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
																						</div>
																					</div>
																				</div>

																				<ul>
																					<li class="fragment fade-up" data-fragment-index="0">Classic priors (monotonicity, symmetry).</li>
																					<br>

																					<li class="fragment fade-up" data-fragment-index="1">Deep Morphology prior.</li>
																				</ul>

																			</section>
																			<section>
																				<div class="container">
																					<div class="col">
																						True Galaxy
																						<img data-src="assets/true_input.png" class="plain"></img>
																					</div>

																					<div class="col">
																						Deep Morphology Prior Solution

																						<img class=" plain" data-src="assets/pix_rec2.png" />

																					</div>

																					<div class="col">
																						Monotonicity + Symmetry Solution
																						<img class=" plain" data-src="assets/scar_rec2.png" />
																					</div>
																				</div>
																			</section>
																		</section>

																		<section>
																			<h3 class="slide-title"> Extending to multi-band images</h3>

																			<img class=" plain" data-src="assets/scarlet_hsc.png" />
																			<div style="float:right; font-size: 25px"><b>Lanusse</b>, Melchior, Moolekamp (2019)<br>
																			</div>
																		</section>

																		<section>
																			<h3 class="slide-title"> Takeaway</h3>
																			<br>
																			<br>
																			<ul>
																				<li> Deep generative models can be used to provide <b class="alert">data driven priors</b>.
																				</li>
																				<br>
																				<br>
																				<li class="fragment"> <b class="alert">Explicit likelihood</b>, uses of all of our physical knowledge.<br>
																					$\Longrightarrow$ The method can be applied for varying PSF, noise, or even different instruments!
																				</li>
																				<br>
																				<br>
																				<li class="fragment"> Iterative optimization can include additional regularization terms.
																					<ul>
																						<li> Ensures fit to data (flux preservation).
																						</li>
																						<li> Can impose physical constraints like positivity.
																						</li>
																					</ul>
																				</li>
																			</ul>
																			<br>
																			<br>

																			<br>
																			<br>
																			<p class="fragment"> But what about <b>uncertainty quantification</b>? </p>
																			<br>
																			<br>
																		</section>



	<section class="inverted" data-background="#000">
		<h2>Can we sample from the full Bayesian posterior $p(y | x)$ to estimate uncertainties?</h2>
	</section>

	<section>
		<h2>Deep Posterior Sampling with Denoising Score Matching</h2>

		<a href="https://arxiv.org/abs/2011.08271"><img src="https://img.shields.io/badge/astro--ph.CO-arXiv%3A2011.08271-B31B1B.svg" class="plain" style="height:25px;" /></a>
		<a href="https://arxiv.org/abs/2011.08698"><img src="https://img.shields.io/badge/stat.ML-arXiv%3A2011.08698-B31B1B.svg" class="plain" style="height:25px;" /></a>
		<hr>
		<div class="container">
			<div class="col">
				<div align="left" style="margin-left: 20px;">
					<h3>Work in collaboration with: <br>
						Benjamin Remy, Zaccharie Ramzi
					</h3>

					<br> <br> <br>

					$\Longrightarrow$ Sample from posterior with gradient-based Monte-Carlo methods
				</div>
			</div>
			<div class="col">
						<img class="plain" data-src="assets/knee.gif" style="width:450px;" />
			</div>
		</div>
		<br>
	</section>

	<section>
		<h3 class="slide-title">The score is all you need!</h3>
		<ul>
			<li> Instead of learning ${\color{orange} \log {\color{orange} p\color{orange}(\color{orange} x\color{orange})}}$, learn $\frac{\color{orange} d \color{orange}\log \color{orange}p\color{orange}(\color{orange}x\color{orange})}{\color{orange} d
				\color{orange}x}$, a.k.a. the <b class="alert">Score Function</b>
				<br>
				<br>
				<ul>
					<li> MAP estimation only need the score! Same is true for <b>Hamiltonian Monte Carlo</b>!
					</li>
				</ul>
				</li>
				<br>
				<li class="fragment" data-fragment-index="0"> The score can be learned efficiently by training a <b class="alert">deep Gaussian denoiser</b> (Denoising Score Matching).
				</li>
				<li class="fragment" data-fragment-index="1"> The score of the full posterior is simply:
					$$\nabla \log p(x |y) = \underbrace{\nabla \log p(y |x)}_{\mbox{known}} \quad + \quad \underbrace{\nabla \log p(x)}_{\mbox{learned}}$$
				</li>
				</ul>
				<br>
				<div class="container">

					<div class="col">
						<img data-src="assets/score_two_moons.png"></img>
					</div>


					<div class="col fragment" data-fragment-index="0">

						<div class="container">
							<div class="col">$\boldsymbol{x}'$
							</div>
							<div class="col">$\boldsymbol{x}$
							</div>
							<div class="col">$\boldsymbol{x}'- \boldsymbol{r}^\star(\boldsymbol{x}', \sigma)$
							</div>
							<div class="col">$\boldsymbol{r}^\star(\boldsymbol{x}', \sigma)$
							</div>
						</div>
						<img data-src="assets/denoised_mnist.png"></img>

						$$\boxed{\boldsymbol{r}^\star(\boldsymbol{x}', \sigma) = \boldsymbol{x}' + \sigma^2 \nabla_{\boldsymbol{x}} \log p_{\sigma^2}(\boldsymbol{x}')}$$
					</div>
				</div>
			</section>

			<section>
				<h3 class="slide-title">Uncertainty quantification in Magnetic Resonance Imaging (MRI)</h3>
				<div style="float:right; font-size: 20px">Ramzi, Remy, <b>Lanusse</b> et al. 2020 		<a href="https://arxiv.org/abs/2011.08698" style='vertical-align:middle; display:inline;'><img src="https://img.shields.io/badge/stat.ML-arXiv%3A2011.08698-B31B1B.svg" class="plain" style="height:25px;" /></a>
				</div>
				<br>
				<br>
				$$\boxed{y = \mathbf{M} \mathbf{F} x + n}$$
				<div><video data-autoplay loop="loop" data-src="assets/knee.mp4" type="video/mp4" style="width: 1280px;" />
				</div>
				<ul>
					<br>
					<li> Learn score $\nabla \log p(x)$ with UNet trained by denoising score matching.
					</li>
					<li> Sample 320x320pix image posterior by Annealed Hamiltonian Monte Carlo.
					</li>
				</ul>
				<br>

				<p class="fragment">$\Longrightarrow$ We can see which parts of the image are well constrained by data, and which regions are <b class="alert">uncertain</b>.</p>
			</section>

			<section>
				<h3 class="slide-title">Probabilistic Mass-Mapping of the HST COSMOS field</h3>
				<div style="float:right; font-size: 20px">Remy, <b>Lanusse</b>, Ramzi et al. 2020 <a href="https://arxiv.org/abs/2011.08271" style='vertical-align:middle; display:inline;'><img src="https://img.shields.io/badge/astro--ph.CO-arXiv%3A2011.08271-B31B1B.svg" class="plain" style="height:25px;" /></a>
				</div>
				$$\boxed{\gamma = \mathbf{P} \kappa + n}$$
				<img data-src="assets/cosmos_massmap.png"></img>
				<br>
				<ul>
					<li><b class="alert">Hybrid prior</b>: theoretical Gaussian on large scale, data-driven on small scales using N-body simulations.
						$$\underbrace{\nabla_{\boldsymbol{\kappa}} \log p(\boldsymbol{\kappa})}_\text{full prior} = \underbrace{\nabla_{\boldsymbol{\kappa}} \log p_{th}(\boldsymbol{\kappa})}_\text{gaussian prior} + \underbrace{\boldsymbol{r}_\theta(\boldsymbol{\kappa}, \nabla_{\boldsymbol{\kappa}} \log p_{th}(\boldsymbol{\kappa}))}_\text{learned residuals}$$
						with $p_{th}(\boldsymbol{\kappa}) = \frac{1}{ \sqrt{ \det 2 \pi \boldsymbol{S}}} \exp \left( -\frac{1}{2} \boldsymbol{\kappa}^\dagger \boldsymbol{S}^{-1} \boldsymbol{\kappa} \right)$, computed from theory.
					</li>
				</ul>
				<br>
				<br>
				<!-- <div class="block fragment">
					<div class="block-title">
						The Ultimate DeepMass
					</div>
					<div class="block-content">
						<ul>
							<li> Uses explicit modeling of the data likelihood.
							</li>
							<li class="fragment"> Full uncertainty quantification thanks to posterior samples.
							</li>
						</ul>
					</div>
				</div> -->
			</section>

			<section>
				<h3 class="slide-title">Conclusion</h3>
				<br>
				<br>
				<br>
				<br>
				<div class="block fragment">
					<div class="block-title">
						Where is Deep Learning interesting for Astronomical Image Processing?
					</div>
					<div class="block-content">
						<ul>
							<li> Extremely efficient at classification tasks.<br>
								$\Longrightarrow$ Improve size and quality of samples for science.
							</li>
							<br>
							<li class="fragment">Restricting Deep Learning to modeling the priors brings robustness and intrepretability.
								<ul>
									<li> Deep Generative Models are perfect for learning data-driven priors.
									</li>
								</ul>
							</li>
							<br>
							<li class="fragment"> Proper <b>Uncertainty Quantification</b> is possible by sampling the Bayesian posterior of the inverse problem.
							</li>
						</ul>

					</div>
				</div>

				<br>
				<br>
				<br>
				<br>

				<p class="fragment"> Thank you!</p>

				<br>
				<br>
			</section>

			<section class="inverted" data-background="#000">
				<h2>Bonus: How to train a generative model from noisy/corrupted data?</h2>
			</section>

		<section>
		<h2>Deep Generative Models for Galaxy Image Simulations</h2>

		<br>
		<a href="https://arxiv.org/abs/2008.03833"><img src="https://img.shields.io/badge/astro--ph.IM-arXiv%3A2008.03833-B31B1B.svg" class="plain" style="height:25px;"/></a>
		<a href="https://github.com/McWilliamsCenter/galsim_hub"><img src="https://badgen.net/badge/icon/github?icon=github&label" class="plain" style="height:25px;"/></a>
		<a href="https://colab.research.google.com/github/McWilliamsCenter/galsim_hub/blob/master/notebooks/GalsimHubDemo.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" class="plain" style="height:25px;"/></a>
		<hr>
		<br>
		<br>
		<div align="left" style="margin-left: 20px;">

			<h3>Work in collaboration with <br>
				Rachel Mandelbaum, Siamak Ravanbakhsh, Chun-Liang Li, Barnabas Poczos, Peter Freeman</h3>
			</div>

			<br>
			<br>

			<div style="float:center; font-size: 25px"><b>Lanusse</b> et al. (2020) <br>
				Ravanbakhsh, <b>Lanusse</b>, et al. (2017)
			</div>
		</section>
		<section>
			<section>
				<h3 class="slide-title"> The weak lensing shape measurement problem</h3>
				<div>
					<img class="plain" data-src="assets/great.jpg" />
				</div>

				<div class="block fragment" >
					<div class="block-title">
						Shape measurement biases
					</div>
					<div class="block-content">
						$$ < e >  = \ (1 + m) \ \gamma \ + \ c $$

						<ul>
							<li class="fragment fade-up"> Can be calibrated on image simulations
							</li>
							<li class="fragment fade-up"> How complex do the simulations need to be?
							</li>
						</ul>
					</div>
				</div>
			</section>
</section>

<section>
	<h3 class="slide-title"> Complications specific to astronomical images: spot the differences!</h3>

	<div class="container">
		<div class="col">
			<img data-src="assets/celeba.png" class="plain" style="height: 450px;" ></img>
			<br>
			CelebA
		</div>
		<div class="col">
			<img data-src="assets/hsc_images.png" class="plain"  style="height: 450px;" ></img>
			<br>
			HSC PDR-2 wide
		</div>
	</div>
	<br>
	<div >
		<ul>
			<li class="fragment"> There is <b class="alert">noise</b></li>
			<li class="fragment"> We have a <b class="alert">Point Spread Function</b></li>
		</ul>
	</div>
</section>

<section>
	<section>
		<h3 class="slide-title" style="position:absolute;top:0;">A Physicist's approach: let's build a model</h3>
		<br>
		<br>
		<div class="container">
			<div class="col">
				<img class="plain fragment" data-src="assets/rand_z_square.png" style="height: 150px" data-fragment-index="4"/>
			</div>
			<div class="col">
				<img class="plain fragment" data-src="assets/cosmos_gal.png" style="width: 200px" data-fragment-index="3"/>
			</div>
			<div class="col">
				<img class="plain fragment" data-src="assets/cosmos_gal_psf.png" style="width: 200px" data-fragment-index="2"/>
			</div>
			<div class="col">
				<img class="plain fragment" data-src="assets/cosmos_gal_pix.png" style="width: 200px" data-fragment-index="1"/>
			</div>
			<div class="col">
				<img class="plain fragment" data-src="assets/cosmos_gal_ground.png" style="width: 200px" data-fragment-index="0"/>
			</div>
		</div>

		<div class="container" style="position:relative; width:1000px; height:50px; margin:0 auto;">
			<div class='col fragment' data-fragment-index='4'> <font size="10"> $\longrightarrow$ </font> <br> $g_\theta$ </div>
			<div class='col fragment' data-fragment-index='3'> <font size="10"> $\longrightarrow$ </font> <br> PSF </div>
			<div class='col fragment' data-fragment-index='2'> <font size="10"> $\longrightarrow$ </font> <br> Pixelation</div>
			<div class='col fragment' data-fragment-index='1'> <font size="10"> $\longrightarrow$ </font> <br> Noise </div>
		</div>

		<div class="container">
			<div class="col">
				<div style="position:relative; width:400px; height:300px; margin:0 auto;">
					<img data-src="assets/pgm_0.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:300px;" data-fragment-index="0"/>
					<img data-src="assets/pgm_1.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:300px;" data-fragment-index="1"/>
					<img data-src="assets/pgm_1.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:350px;" data-fragment-index="2"/>
					<img data-src="assets/pgm_2.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:350px;" data-fragment-index="3"/>
					<img data-src="assets/pgm_3.png" class="plain fragment " style="position:absolute;top:0;left:0;height:300px;" data-fragment-index="4"/>
				</div>
			</div>
			<div class=" col">
				<div class="block fragment" data-fragment-index="0">
					<div class="block-title">
						Probabilistic model
					</div>
					<div class="block-content">
						<div style="position:relative; width:400px; height:100px; margin:0 auto;">
							<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="0"> $$ x \sim ? $$ </div>
							<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="1"> $$ x \sim \mathcal{N}(z, \Sigma) \quad z \sim ? $$<br>latent $z$ is a denoised galaxy image</div>
							<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="2"> $$ x \sim \mathcal{N}( \mathbf{P} z, \Sigma) \quad z \sim ?$$<br>latent $z$ is a super-resolved and denoised galaxy image</div>
							<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="3"> $$ x \sim \mathcal{N}( \mathbf{P} (\Pi \ast z), \Sigma) \quad z \sim ? $$<br>latent $z$ is a deconvolved, super-resolved, and denoised galaxy image </div>
							<div class="plain fragment " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="4"> $$ x \sim \mathcal{N}( \mathbf{P} (\Pi \ast g_\theta(z)), \Sigma) \quad z \sim \mathcal{N}(0, \mathbf{I}) $$ <br>latent $z$ is a Gaussian sample<br> <b class="alert"> $\theta$ are parameters of the model</b> </div>
						</div>
						<br>
						<br>
						<br>
					</div>
				</div>
			</div>
		</div>
		<div class="fragment"> $\Longrightarrow$ <b class="alert"> Decouples the morphology model from the observing conditions</b>.</div>
	</section>

	<section>
		<h3 class="slide-title">How to train your <s>dragon</s> model</h3>
		<div class="container">
			<div class="col">
				<img data-src="assets/pgm.png" class="plain" style="height: 300px;" ></img>
			</div>
			<div class="col">
				<ul>
					<li> Training the generative amounts to finding $\theta_\star$ that
						<b>maximizes the marginal likelihood</b> of the model:
						$$p_\theta(x | \Sigma, \Pi) = \int \mathcal{N}( \Pi \ast g_\theta(z), \Sigma) \ p(z) \ dz$$
						<div> $\Longrightarrow$ This is <b class="alert">generally intractable</b></div>
					</li>
					<br>
					<li class="fragment fade-up"> Efficient training of parameter $\theta$ is made possible by <b class="alert">Amortized Variational Inference</b>.
					</li>
				</ul>
			</div>
		</div>

		<div class="block fragment fade-up">
			<div class="block-title">
				Auto-Encoding Variational Bayes (Kingma & Welling, 2014)
			</div>
			<div class="block-content">
				<ul>
					<li class="fragment fade-up"> We introduce a <b>parametric distribution</b> $q_\phi(z | x, \Pi, \Sigma)$ which aims to model the
						posterior $p_{\theta}(z | x, \Pi, \Sigma)$.
					</li>
					<br>
					<li class="fragment fade-up"> Working out the KL divergence between these two distributions leads to:

						$$\log p_\theta(x | \Sigma, \Pi) \quad \geq \quad - \mathbb{D}_{KL}\left( q_\phi(z | x, \Sigma, \Pi) \parallel p(z) \right) \quad + \quad \mathbb{E}_{z \sim q_{\phi}(. | x, \Sigma, \Pi)} \left[ \log p_\theta(x | z, \Sigma, \Pi)  \right]$$

						$\Longrightarrow$ This is the <b>Evidence Lower-Bound</b>, which is differentiable with respect to $\theta$ and $\phi$.
					</li>
				</ul>
			</div>
		</div>
	</section>

	<section>
		<h3 class="slide-title">The famous Variational Auto-Encoder</h3>
		<img data-src="assets/vae.png" class="plain" style="height: 450px;"> </img>
		<br>
		<br>
		$$\log p_\theta(x| \Sigma, \Pi ) \geq - \underbrace{\mathbb{D}_{KL}\left( q_\phi(z | x, \Sigma, \Pi) \parallel p(z) \right)}_{\mbox{code regularization}} + \underbrace{\mathbb{E}_{z \sim q_{\phi}(. | x, \Sigma, \Pi)} \left[ \log p_\theta(x | z, \Sigma, \Pi)  \right]}_{\mbox{reconstruction error}} $$
	</section>


	    <section>
	  				<h3 class="slide-title"> Sampling from the model</h3>
	            <div class="container">
	            <div class="col fragment fade-up">
	              <img data-src="assets/vae_samples_bad.png" class="plain" ></img>
	              Woups... what's going on?
	            </div>
	            <div class="col">
	              <img data-src="assets/latent_space.png" class="plain fragment fade-up" ></img>
	            </div>
	          </div>
	    </section>

	    <section>
				<h3 class="slide-title"> Tradeoff between code regularization and image quality</h3>

	      <br>
	      $$\log p_\theta(x| \Sigma, \Pi ) \geq - \underbrace{\mathbb{D}_{KL}\left( q_\phi(z | x, \Sigma, \Pi) \parallel p(z) \right)}_{\mbox{code regularization}} + \underbrace{\mathbb{E}_{z \sim q_{\phi}(. | x, \Sigma, \Pi)} \left[ \log p_\theta(x | z, \Sigma, \Pi)  \right]}_{\mbox{reconstruction error}} $$

	      <img data-src="assets/sdss_ae_kl.png" class="plain" ></img>

	    </section>

	    <section data-background-image=https://media.giphy.com/media/3o85xIO33l7RlmLR4I/source.gif>
	    </section>

		<section>
			<h3 class="slide-title"> Latent space modeling with Normalizing Flows</h3>
			<br>
			$\Longrightarrow$ All we need to do is <b class="alert">sample from the aggregate posterior</b> of the data instead of sampling from the prior.

		<br>
		<br>

		<div class="container">
		<div class="col">
			<img data-src="assets/flow_dinh_1.png" class="plain fragment fade-up" data-fragment-index="1"></img>
			<img data-src="assets/flow_dinh_2.png" class="plain fragment fade-up" data-fragment-index="3"></img>

			<br>
			<div class="fragment fade-up" style="float:right; font-size: 20px" data-fragment-index="1">Dinh et al. 2016</div>
		</div>
		<div class="col">
							<div class="block fragment fade-up" data-fragment-index="1">
							<div class="block-title">
							 Normalizing Flows
							</div>
							<div class="block-content">
								<ul>
									<li> Assumes a <b class="alert">bijective</b> mapping between
										data space $x$ and latent space $z$ with prior $p(z)$:
										$$ z = f_{\theta} ( x ) \qquad \mbox{and} \qquad x = f^{-1}_{\theta}(z)$$
									</li>
									<li class="fragment" data-fragment-index="2"> Admits an explicit marginal likelihood:
										$$ \log p_\theta(x) = \log p(z) + \log \left| \frac{\partial f_\theta}{\partial x}  \right|(x)    $$
									</li>
								</ul>
						</div>
						</div>
						<br>
							<br>
							<br>
							<br>
		</div>
</div>

		</section>
	    </section>

	<section>
		<section>
			<h3 class="slide-title"> Flow-VAE samples</h3>
			<br>
			<br>
			<img class="current-visible plain" data-src="assets/lanusse2020_figure1.png"/>
		</section>

		<section>
			<h3 class="slide-title">Second order moments</h3>
			<img class="current-visible plain" data-src="assets/lanusse2020_fig6a.png" style="width:550px;"/><br>
			<img class="current-visible plain" data-src="assets/lanusse2020_fig6b.png" style="width:550px;"/>
		</section>

		<section>
			<h3 class="slide-title"> Testing galaxy morphologies </h3>

			<br>
			<br>

			<img data-src="assets/gini_m20.png" class="plain"></img>

			<br>
			<br>
		</section>
	</section>

    <section>
      <h3 class="slide-title">Bayesian Inference a.k.a. Uncertainty Quantification</h3>
      <div class="container">
          <div class="col">
            <img data-src="assets/pgm.png" class="plain" style="height: 250px;" ></img>
          </div>
          <div class="col">
            The Bayesian view of the problem:
                 $$ p(z | x ) \propto p_\theta(x | z, \Sigma, \mathbf{\Pi}) p(z)$$
             where:
             <br>
               <ul>
                 <li>$p( z | x )$ is the <b class="alert">posterior</b></li>
                 <li>$p( x | z )$ is the data likelihood, <b class="alert">contains the physics</b></li>
                 <li>$p( z )$ is the <b>prior</b> </li>
               </ul>
          </div>
      </div>

      <div class="container">
          <div class="col">
            <div style="position:relative; width:200px; height:200px; margin:0 auto;">
              <img class="plain fragment current-visible" data-src="assets/cosmos_gal_ground.png" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="0" />
              <img class="plain fragment" data-src="assets/cosmos_gal.png" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="1"/>
            </div>
            <div class="container" style="position:relative; width:200px; height:50px; margin:0 auto;">
              <div class='col fragment current-visible' data-fragment-index='0' style="position:absolute;top:0;left:0;width:200px;"> Data<br> $x_n$</div>
              <div class='col fragment' data-fragment-index='1' style="position:absolute;top:0;left:0;width:200px;"> Truth<br> $x_0$ </div>
            </div>
            <br>
          </div>

          <div class="col fragment" data-fragment-index='0' >
            <div style="position:relative; width:200px; height:200px; margin:0 auto;">
              <div><video data-autoplay data-loop data-src="assets/rec_samples.mp4" type="video/mp4" style="height: 200px;"/>
              </div>
            </div>
            <div>Posterior samples<br> $g_\theta(z)$</div>
          </div>

          <div class="col">
            <div style="position:relative; width:200px; height:200px; margin:0 auto;">
              <div><video class="fragment current-visible" data-autoplay data-loop data-src="assets/rec_lsst.mp4" type="video/mp4" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="0"/></div>
              <img class="plain fragment " data-src="assets/rec_median.png" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="1"/>
            </div>

            <div class="container" style="position:relative; width:200px; height:50px; margin:0 auto;">
              <div class='col fragment current-visible' data-fragment-index='0' style="position:absolute;top:0;left:0;width:200px;">  <br> $\mathbf{P} (\Pi \ast g_\theta(z))$</div>
              <div class='col fragment' data-fragment-index='1' style="position:absolute;top:0;left:0;width:200px;"> Median </div>
            </div>
          </div>

          <div class="col">
            <div style="position:relative; width:200px; height:200px; margin:0 auto;">
              <div><video class="fragment current-visible" data-autoplay data-loop data-src="assets/res_lsst.mp4" type="video/mp4" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="0"/></div>
              <img class="plain fragment " data-src="assets/rec_std.png" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="1"/>
            </div>

            <div class="container" style="position:relative; width:200px; height:50px; margin:0 auto;">
              <div class='col fragment current-visible' data-fragment-index='0' style="position:absolute;top:0;left:0;width:200px;"> Data residuals <br> $x_n - \mathbf{P} (\Pi \ast g_\theta(z))$</div>
              <div class='col fragment' data-fragment-index='1' style="position:absolute;top:0;left:0;width:200px;"> Standard Deviation </div>
            </div>
          </div>
      </div>
      <div class="fragment"> $\Longrightarrow$ <b class="alert">Uncertainties are fully captured by the posterior</b>.</div>
    </section>
  </section>


	   <section>
	     <h3 class="slide-title">How to perform efficient posterior inference?</h3>
	     <div class="container">

	       <div class="col">
	         <img class="plain " data-src="assets/cosmos_gal_ground.png" style="height:200px;" />
	       </div>

	       <div class="col">
	         <div style="height:200px"><video data-autoplay data-loop data-src="assets/rec_samples.mp4" type="video/mp4" style="height: 200px;"/>
	         </div>
	       </div>
	       <hr style="width: 2px; height: 200px; background: white; border: none;" />
	       <div class="col">
	          <img class="fragment plain" data-fragment-index="3" data-src="assets/deep_uq_4.png" style="height:200px"/>
	       </div>

	       <div class="col">
	         <img class="fragment plain"  data-fragment-index="3" data-src="assets/deep_uq_contours.png"  style="height:200px"/>
	       </div>

	       <div class="col">
	         <img class="fragment plain"  data-fragment-index="3" data-src="assets/deep_uq_recs.png" style="height:200px" />
	       </div>
	     </div>

	          <div style="float:right; font-size: 20px" class="fragment" data-fragment-index="3"><a href="https://arxiv.org/abs/1910.10046">(Böhm, Lanusse, Seljak 2019)</a></div>
	         <ul>
	           <li class="fragment" data-fragment-index="1">Posterior fitting by <b class="alert">Variational Inference</b>
	             <br>
	              $$ \mathrm{ELBO} = - \mathbb{D}_{KL}\left( q_\phi(z) \parallel p(z) \right) \quad + \quad \mathbb{E}_{z \sim q_{\phi}} \left[ \log p_\theta(x_n | z, \Sigma_n, \Pi_n)  \right]$$
	           </li>

	           <li class="fragment" data-fragment-index="3">Posterior fitting by <b class="alert">$EL_{2}O$</b> <br>
	             $$EL_2O = \arg \min_\theta \mathbb{E}_{z \sim p^{\prime}} \sum_i \alpha_i \parallel \nabla_{z}^n \ln q_\theta(z) - \nabla_{z}^{n} \ln p(z | x_n, \Sigma_n, \Pi_n)  \parallel_2^2$$See <a href="https://arxiv.org/abs/1901.04454"> (Seljak & Yu, 2019)</a> for more details.
	           </li>
	           <br>
	           <li class="fragment" data-fragment-index="5">Or your favorite method...</li>
	         </ul>
	    </section>



		</div>
	</div>

	<style>
		/* .reveal .slides {
			border: 5px solid red;
			min-height: 100%;
			width: 128mm;
			height: 96mm;
		} */

		.reveal .block {
			background-color: #191919;
			margin-left: 20px;
			margin-right: 20px;
			text-align: left;
			padding-bottom: 0.1em;
		}

		.reveal .block-title {
			background-color: #333333;
			padding: 8px 35px 8px 14px;
			color: #FFAA7F;
			font-weight: bold;
		}

		.reveal .block-content {
			padding: 8px 35px 8px 14px;
		}

		.reveal .slide-title {
			border-left: 5px solid white;
			text-align: left;
			margin-left: 20px;
			padding-left: 20px;
		}

		.reveal .alert {
			color: #FFAA7F;
			font-weight: bold;
		}

		.reveal .inverted {
			filter: invert(100%);
		}

		/*
	/* .reveal .alert {
	padding:8px 35px 8px 14px; margin-bottom:18px;
	text-shadow:0 1px 0 rgba(255,255,255,1);
	border:5px solid #FFAA7F;
	-webkit-border-radius: 14px; -moz-border-radius: 14px;
	border-radius:14px
	background-position: 10px 10px;
	background-repeat: no-repeat;
	background-size: 38px;
	padding-left: 30px; /* 55px; if icon
	}
	.reveal .alert-block {padding-top:14px; padding-bottom:14px}
	.reveal .alert-block > p, .alert-block > ul {margin-bottom:1em}
	/*.reveal .alert li {margin-top: 1em}
	.reveal .alert-block p+p {margin-top:5px} */
	</style>


	<script src="reveal.js/dist/reveal.js"></script>
	<script src="reveal.js/plugin/notes/notes.js"></script>
	<script src="reveal.js/plugin/markdown/markdown.js"></script>
	<script src="reveal.js/plugin/highlight/highlight.js"></script>
	<script src="reveal.js/plugin/math/math.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			controls: false,

			//center: false,
			hash: true,

			// Visibility rule for backwards navigation arrows; "faded", "hidden"
			// or "visible"
			controlsBackArrows: 'hidden',

			// Display a presentation progress bar
			progress: true,

			// Display the page number of the current slide
			slideNumber: true,

			transition: 'slide', // none/fade/slide/convex/concave/zoom

			// The "normal" size of the presentation, aspect ratio will be preserved
			// when the presentation is scaled to fit different resolutions. Can be
			// specified using percentage units.
			width: 1280,
			height: 720,

			// Factor of the display size that should remain empty around the content
			margin: 0.1,

			// Bounds for smallest/largest possible scale to apply to content
			minScale: 0.2,
			maxScale: 1.5,

			autoPlayMedia: true,

			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath],

			dependencies: [{
					src: 'reveal.js/plugin/markdown/marked.js'
				},
				{
					src: 'reveal.js/plugin/markdown/markdown.js'
				},
				{
					src: 'reveal.js/plugin/notes/notes.js',
					async: true
				},
				{
					src: 'reveal.js/plugin/math/math.js',
					async: true
				},
				{
					src: 'reveal.js/plugin/reveal.js-d3/reveald3.js'
				},
				{
					src: 'reveal.js/plugin/reveal.js-plugins/chart/Chart.min.js'
				},
				{
					src: 'reveal.js/plugin/reveal.js-plugins/chart/csv2chart.js'
				},
				{
					src: 'reveal.js/plugin/highlight/highlight.js',
					async: true
				},
			]

		});
	</script>
</body>

</html>
